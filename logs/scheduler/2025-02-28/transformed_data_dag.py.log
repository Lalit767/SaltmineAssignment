[2025-02-28T12:41:28.052+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:41:28.071+0000] {processor.py:186} INFO - Started process (PID=171) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:28.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:41:28.076+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:41:28.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:28.092+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:41:28.088+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:41:28.094+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:28.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.100 seconds
[2025-02-28T12:41:58.763+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:41:58.774+0000] {processor.py:186} INFO - Started process (PID=191) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:58.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:41:58.779+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:41:58.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:58.797+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:41:58.794+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:41:58.798+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:41:58.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.063 seconds
[2025-02-28T12:42:29.151+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:42:29.161+0000] {processor.py:186} INFO - Started process (PID=211) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:29.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:42:29.165+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:42:29.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:29.182+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:42:29.178+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:42:29.183+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:29.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.066 seconds
[2025-02-28T12:42:59.848+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:42:59.858+0000] {processor.py:186} INFO - Started process (PID=231) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:59.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:42:59.862+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:42:59.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:59.878+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:42:59.874+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:42:59.879+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:42:59.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.066 seconds
[2025-02-28T12:43:30.457+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:43:30.470+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:43:30.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:43:30.474+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:43:30.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:43:30.487+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:43:30.484+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:43:30.488+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:43:30.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.061 seconds
[2025-02-28T12:44:01.063+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:44:01.073+0000] {processor.py:186} INFO - Started process (PID=271) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:01.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:44:01.076+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:44:01.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:01.090+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:44:01.086+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:44:01.091+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:01.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T12:44:31.460+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:44:31.468+0000] {processor.py:186} INFO - Started process (PID=291) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:31.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:44:31.472+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:44:31.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:31.485+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:44:31.481+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:44:31.486+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:44:31.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T12:45:02.127+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:45:02.139+0000] {processor.py:186} INFO - Started process (PID=311) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:02.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:45:02.143+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:45:02.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:02.155+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:45:02.149+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:45:02.156+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:02.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.102 seconds
[2025-02-28T12:45:32.815+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:45:32.826+0000] {processor.py:186} INFO - Started process (PID=331) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:32.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:45:32.830+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:45:32.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:32.851+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:45:32.847+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:45:32.852+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:45:32.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.069 seconds
[2025-02-28T12:46:03.428+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:46:03.440+0000] {processor.py:186} INFO - Started process (PID=351) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:03.441+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:46:03.444+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:46:03.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:03.463+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:46:03.459+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:46:03.464+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:03.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.065 seconds
[2025-02-28T12:46:34.118+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:46:34.131+0000] {processor.py:186} INFO - Started process (PID=371) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:34.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:46:34.135+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:46:34.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:34.155+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:46:34.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:46:34.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:46:34.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.076 seconds
[2025-02-28T12:47:04.758+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:47:04.770+0000] {processor.py:186} INFO - Started process (PID=391) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:04.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:47:04.776+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:47:04.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:04.795+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:47:04.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:47:04.796+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:04.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.070 seconds
[2025-02-28T12:47:35.460+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:47:35.475+0000] {processor.py:186} INFO - Started process (PID=411) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:35.476+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:47:35.480+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:47:35.480+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:35.502+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:47:35.498+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:47:35.503+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:47:35.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T12:48:05.942+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:48:05.954+0000] {processor.py:186} INFO - Started process (PID=431) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:05.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:48:05.960+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:48:05.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:05.978+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:48:05.975+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:48:05.979+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:06.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.075 seconds
[2025-02-28T12:48:36.478+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:48:36.487+0000] {processor.py:186} INFO - Started process (PID=451) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:36.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:48:36.491+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:48:36.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:36.504+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:48:36.500+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:48:36.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:48:36.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T12:49:06.978+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:49:06.987+0000] {processor.py:186} INFO - Started process (PID=471) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:06.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:49:06.993+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:49:06.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:07.010+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:49:07.004+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:49:07.011+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:07.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.064 seconds
[2025-02-28T12:49:37.479+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:49:37.488+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:37.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:49:37.494+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:49:37.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:37.508+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:49:37.504+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:49:37.509+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:49:37.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.061 seconds
[2025-02-28T12:50:08.141+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:50:08.150+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:08.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:50:08.155+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:50:08.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:08.167+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:50:08.164+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:50:08.169+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:08.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.061 seconds
[2025-02-28T12:50:38.830+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:50:38.839+0000] {processor.py:186} INFO - Started process (PID=531) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:38.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:50:38.842+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:50:38.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:38.858+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:50:38.855+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:50:38.859+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:50:38.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T12:51:09.514+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:51:09.522+0000] {processor.py:186} INFO - Started process (PID=551) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:09.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:51:09.525+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:51:09.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:09.538+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:51:09.535+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:51:09.540+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:09.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T12:51:40.075+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:51:40.084+0000] {processor.py:186} INFO - Started process (PID=571) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:40.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:51:40.088+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:51:40.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:40.102+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:51:40.099+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:51:40.103+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:51:40.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T12:52:10.605+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:52:10.613+0000] {processor.py:186} INFO - Started process (PID=591) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:10.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:52:10.619+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:52:10.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:10.632+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:52:10.629+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:52:10.633+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:10.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T12:52:41.282+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:52:41.290+0000] {processor.py:186} INFO - Started process (PID=611) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:41.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:52:41.296+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:52:41.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:41.310+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:52:41.307+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:52:41.311+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:52:41.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.062 seconds
[2025-02-28T12:53:11.963+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:53:11.972+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:11.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:53:11.975+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:53:11.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:11.988+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:53:11.984+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:53:11.990+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:12.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T12:53:42.665+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:53:42.674+0000] {processor.py:186} INFO - Started process (PID=651) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:42.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:53:42.678+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:53:42.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:42.694+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:53:42.691+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:53:42.696+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:53:42.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T12:54:13.352+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:54:13.362+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:13.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:54:13.366+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:54:13.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:13.378+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:54:13.375+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:54:13.380+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:13.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T12:54:43.843+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:54:43.852+0000] {processor.py:186} INFO - Started process (PID=691) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:43.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:54:43.857+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:54:43.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:43.872+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:54:43.867+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:54:43.874+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:54:43.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T12:55:14.519+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:55:14.527+0000] {processor.py:186} INFO - Started process (PID=711) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:14.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:55:14.533+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:55:14.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:14.548+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:55:14.544+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:55:14.549+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:14.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T12:55:45.209+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:55:45.219+0000] {processor.py:186} INFO - Started process (PID=731) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:45.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:55:45.226+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:55:45.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:45.245+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:55:45.241+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:55:45.247+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:55:45.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.072 seconds
[2025-02-28T12:56:15.965+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:56:15.975+0000] {processor.py:186} INFO - Started process (PID=751) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:15.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:56:15.980+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:56:15.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:16.001+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:56:15.996+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:56:16.003+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:16.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.072 seconds
[2025-02-28T12:56:46.717+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:56:46.728+0000] {processor.py:186} INFO - Started process (PID=771) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:46.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:56:46.734+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:56:46.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:46.748+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:56:46.744+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:56:46.750+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:56:46.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.067 seconds
[2025-02-28T12:57:17.223+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:57:17.237+0000] {processor.py:186} INFO - Started process (PID=791) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:17.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:57:17.242+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:57:17.242+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:17.283+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:57:17.255+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:57:17.289+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:17.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T12:57:47.912+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:57:47.921+0000] {processor.py:186} INFO - Started process (PID=811) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:47.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:57:47.929+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:57:47.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:47.944+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:57:47.941+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:57:47.945+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:57:47.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.063 seconds
[2025-02-28T12:58:18.237+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T12:58:18.260+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:58:18.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T12:58:18.268+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:58:18.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:58:18.296+0000] {logging_mixin.py:190} INFO - [2025-02-28T12:58:18.290+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T12:58:18.297+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T12:58:18.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T13:19:58.788+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:19:58.805+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:19:58.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:19:58.813+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:19:58.812+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:19:58.838+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:19:58.830+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:19:58.841+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:19:58.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T13:20:29.565+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:20:29.643+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:20:29.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:20:29.671+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:20:29.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:20:29.789+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:20:29.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:20:29.807+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:20:30.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.521 seconds
[2025-02-28T13:37:49.447+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:37:49.464+0000] {processor.py:186} INFO - Started process (PID=893) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:37:49.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:37:49.470+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:37:49.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:37:49.495+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:37:49.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:37:49.498+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:37:49.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T13:38:19.757+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:38:19.827+0000] {processor.py:186} INFO - Started process (PID=913) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:19.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:38:19.845+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:38:19.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:19.921+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:38:19.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:38:19.938+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:20.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.335 seconds
[2025-02-28T13:38:50.697+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:38:50.736+0000] {processor.py:186} INFO - Started process (PID=933) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:50.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:38:50.751+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:38:50.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:50.806+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:38:50.791+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:38:50.813+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:38:50.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.235 seconds
[2025-02-28T13:39:21.611+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:39:21.649+0000] {processor.py:186} INFO - Started process (PID=953) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:21.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:39:21.670+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:39:21.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:21.734+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:39:21.719+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:39:21.739+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:21.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.252 seconds
[2025-02-28T13:39:52.143+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:39:52.177+0000] {processor.py:186} INFO - Started process (PID=973) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:52.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:39:52.209+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:39:52.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:52.271+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:39:52.252+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:39:52.276+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:39:52.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.259 seconds
[2025-02-28T13:40:23.435+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:40:23.462+0000] {processor.py:186} INFO - Started process (PID=993) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:40:23.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:40:23.473+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:40:23.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:40:23.511+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:40:23.501+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:40:23.516+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:40:23.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.168 seconds
[2025-02-28T13:47:49.292+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:47:50.363+0000] {processor.py:186} INFO - Started process (PID=1013) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:47:50.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:47:50.405+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:47:50.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:47:50.502+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:47:50.482+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:47:50.516+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:47:50.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 1.834 seconds
[2025-02-28T13:48:21.001+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:48:21.034+0000] {processor.py:186} INFO - Started process (PID=1033) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:21.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:48:21.049+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:48:21.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:21.121+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:48:21.106+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:48:21.124+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:21.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.251 seconds
[2025-02-28T13:48:51.777+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:48:51.786+0000] {processor.py:186} INFO - Started process (PID=1053) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:51.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:48:51.790+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:48:51.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:51.803+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:48:51.800+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:48:51.805+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:48:51.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T13:49:22.314+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:49:22.324+0000] {processor.py:186} INFO - Started process (PID=1073) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:22.325+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:49:22.328+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:49:22.328+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:22.345+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:49:22.339+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:49:22.347+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:22.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.065 seconds
[2025-02-28T13:49:52.878+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:49:52.887+0000] {processor.py:186} INFO - Started process (PID=1093) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:52.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:49:52.892+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:49:52.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:52.906+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:49:52.902+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:49:52.908+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:49:52.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T13:50:23.425+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:50:23.434+0000] {processor.py:186} INFO - Started process (PID=1113) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:23.434+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:50:23.438+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:50:23.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:23.452+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:50:23.448+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:50:23.453+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:23.478+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T13:50:54.040+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:50:54.052+0000] {processor.py:186} INFO - Started process (PID=1133) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:54.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:50:54.057+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:50:54.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:54.075+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:50:54.070+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:50:54.076+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:50:54.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.067 seconds
[2025-02-28T13:51:24.612+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:51:24.621+0000] {processor.py:186} INFO - Started process (PID=1153) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:24.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:51:24.625+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:51:24.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:24.638+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:51:24.634+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:51:24.639+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:24.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T13:51:55.194+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:51:55.203+0000] {processor.py:186} INFO - Started process (PID=1173) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:55.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:51:55.213+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:51:55.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:55.231+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:51:55.227+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:51:55.232+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:51:55.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.074 seconds
[2025-02-28T13:52:25.770+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:52:25.779+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:25.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:52:25.783+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:52:25.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:25.796+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:52:25.793+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:52:25.797+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:25.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T13:52:56.353+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:52:56.363+0000] {processor.py:186} INFO - Started process (PID=1213) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:56.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:52:56.368+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:52:56.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:56.382+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:52:56.379+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:52:56.384+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:52:56.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T13:53:26.901+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:53:26.911+0000] {processor.py:186} INFO - Started process (PID=1233) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:26.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:53:26.914+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:53:26.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:26.928+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:53:26.924+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:53:26.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:26.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T13:53:57.590+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:53:57.599+0000] {processor.py:186} INFO - Started process (PID=1253) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:57.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:53:57.603+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:53:57.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:57.618+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:53:57.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:53:57.620+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:53:57.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.063 seconds
[2025-02-28T13:54:28.153+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:54:28.162+0000] {processor.py:186} INFO - Started process (PID=1273) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:28.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:54:28.165+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:54:28.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:28.179+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:54:28.175+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:54:28.180+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:28.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T13:54:58.718+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:54:58.727+0000] {processor.py:186} INFO - Started process (PID=1293) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:58.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:54:58.731+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:54:58.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:58.745+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:54:58.741+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:54:58.746+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:54:58.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T13:55:29.264+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:55:29.274+0000] {processor.py:186} INFO - Started process (PID=1313) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:29.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:55:29.280+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:55:29.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:29.295+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:55:29.291+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:55:29.296+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:29.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.067 seconds
[2025-02-28T13:55:59.844+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:55:59.853+0000] {processor.py:186} INFO - Started process (PID=1333) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:59.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:55:59.857+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:55:59.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:59.871+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:55:59.867+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:55:59.872+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:55:59.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T13:56:30.399+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:56:30.411+0000] {processor.py:186} INFO - Started process (PID=1353) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:56:30.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:56:30.418+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:56:30.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:56:30.453+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:56:30.440+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:56:30.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:56:30.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.102 seconds
[2025-02-28T13:57:00.999+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:57:01.007+0000] {processor.py:186} INFO - Started process (PID=1373) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:01.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:57:01.011+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:57:01.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:01.024+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:57:01.021+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:57:01.025+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:01.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T13:57:31.601+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:57:31.610+0000] {processor.py:186} INFO - Started process (PID=1393) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:31.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:57:31.614+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:57:31.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:31.627+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:57:31.623+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:57:31.629+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:57:31.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T13:58:02.172+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:58:02.180+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:02.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:58:02.184+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:58:02.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:02.196+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:58:02.193+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:58:02.197+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:02.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.052 seconds
[2025-02-28T13:58:32.889+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:58:32.904+0000] {processor.py:186} INFO - Started process (PID=1433) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:32.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:58:32.909+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:58:32.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:32.921+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:58:32.918+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:58:32.923+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:58:32.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.064 seconds
[2025-02-28T13:59:03.450+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:59:03.458+0000] {processor.py:186} INFO - Started process (PID=1453) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:03.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:59:03.462+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:59:03.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:03.475+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:59:03.471+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:59:03.476+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:03.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T13:59:33.982+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T13:59:33.991+0000] {processor.py:186} INFO - Started process (PID=1473) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:33.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T13:59:33.994+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:59:33.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:34.008+0000] {logging_mixin.py:190} INFO - [2025-02-28T13:59:34.004+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T13:59:34.009+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T13:59:34.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T14:00:04.529+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:00:04.537+0000] {processor.py:186} INFO - Started process (PID=1493) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:04.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:00:04.541+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:00:04.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:04.552+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:00:04.549+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:00:04.553+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:04.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.046 seconds
[2025-02-28T14:00:35.012+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:00:35.019+0000] {processor.py:186} INFO - Started process (PID=1513) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:35.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:00:35.025+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:00:35.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:35.039+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:00:35.035+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:00:35.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:00:35.062+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T14:01:05.541+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:01:05.585+0000] {processor.py:186} INFO - Started process (PID=1533) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:05.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:01:05.597+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:01:05.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:05.637+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:01:05.630+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:01:05.640+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:05.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.136 seconds
[2025-02-28T14:01:36.149+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:01:36.158+0000] {processor.py:186} INFO - Started process (PID=1553) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:36.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:01:36.162+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:01:36.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:36.175+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:01:36.172+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:01:36.177+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:01:36.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T14:02:06.700+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:02:06.709+0000] {processor.py:186} INFO - Started process (PID=1573) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:06.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:02:06.712+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:02:06.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:06.725+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:02:06.722+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:02:06.727+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:06.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T14:02:37.266+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:02:37.275+0000] {processor.py:186} INFO - Started process (PID=1593) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:37.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:02:37.279+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:02:37.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:37.292+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:02:37.289+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:02:37.294+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:02:37.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.166 seconds
[2025-02-28T14:03:08.050+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:03:08.060+0000] {processor.py:186} INFO - Started process (PID=1613) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:08.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:03:08.065+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:03:08.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:08.078+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:03:08.074+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:03:08.079+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:08.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T14:03:38.615+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:03:38.623+0000] {processor.py:186} INFO - Started process (PID=1633) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:38.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:03:38.627+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:03:38.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:38.640+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:03:38.636+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:03:38.641+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:03:38.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T14:04:09.191+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:04:09.200+0000] {processor.py:186} INFO - Started process (PID=1653) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:09.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:04:09.204+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:04:09.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:09.217+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:04:09.213+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:04:09.218+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:09.243+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T14:04:39.791+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:04:39.801+0000] {processor.py:186} INFO - Started process (PID=1673) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:39.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:04:39.805+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:04:39.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:39.818+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:04:39.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:04:39.819+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:04:39.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:05:10.410+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:05:10.418+0000] {processor.py:186} INFO - Started process (PID=1693) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:10.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:05:10.422+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:05:10.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:10.435+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:05:10.431+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:05:10.436+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:10.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T14:05:40.976+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:05:40.986+0000] {processor.py:186} INFO - Started process (PID=1713) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:40.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:05:40.990+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:05:40.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:41.004+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:05:41.001+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:05:41.006+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:05:41.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T14:06:11.666+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:06:11.682+0000] {processor.py:186} INFO - Started process (PID=1733) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:11.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:06:11.686+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:06:11.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:11.701+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:06:11.697+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:06:11.702+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:11.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.064 seconds
[2025-02-28T14:06:42.295+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:06:42.305+0000] {processor.py:186} INFO - Started process (PID=1753) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:42.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:06:42.309+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:06:42.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:42.322+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:06:42.319+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:06:42.324+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:06:42.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:07:12.956+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:07:12.968+0000] {processor.py:186} INFO - Started process (PID=1773) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:12.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:07:12.982+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:07:12.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:13.061+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:07:13.004+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:07:13.068+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:13.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.164 seconds
[2025-02-28T14:07:43.638+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:07:43.647+0000] {processor.py:186} INFO - Started process (PID=1793) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:43.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:07:43.651+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:07:43.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:43.665+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:07:43.662+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:07:43.667+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:07:43.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:08:14.370+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:08:14.383+0000] {processor.py:186} INFO - Started process (PID=1813) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:14.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:08:14.390+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:08:14.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:14.407+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:08:14.403+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:08:14.408+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:14.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.076 seconds
[2025-02-28T14:08:45.004+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:08:45.014+0000] {processor.py:186} INFO - Started process (PID=1833) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:45.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:08:45.018+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:08:45.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:45.030+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:08:45.027+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:08:45.032+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:08:45.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T14:09:16.020+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:09:16.030+0000] {processor.py:186} INFO - Started process (PID=1853) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:16.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:09:16.036+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:09:16.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:16.052+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:09:16.048+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:09:16.053+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:16.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.063 seconds
[2025-02-28T14:09:46.722+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:09:46.730+0000] {processor.py:186} INFO - Started process (PID=1873) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:46.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:09:46.734+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:09:46.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:46.747+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:09:46.743+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:09:46.748+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:09:46.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T14:10:17.516+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:10:17.525+0000] {processor.py:186} INFO - Started process (PID=1893) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:17.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:10:17.529+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:10:17.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:17.541+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:10:17.538+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:10:17.542+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:17.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.075 seconds
[2025-02-28T14:10:48.113+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:10:48.129+0000] {processor.py:186} INFO - Started process (PID=1913) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:48.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:10:48.134+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:10:48.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:48.156+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:10:48.150+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:10:48.159+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:10:48.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.092 seconds
[2025-02-28T14:11:18.695+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:11:18.703+0000] {processor.py:186} INFO - Started process (PID=1933) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:18.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:11:18.706+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:11:18.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:18.718+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:11:18.715+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:11:18.720+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:18.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T14:11:49.330+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:11:49.346+0000] {processor.py:186} INFO - Started process (PID=1953) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:49.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:11:49.356+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:11:49.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:49.381+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:11:49.374+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:11:49.384+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:11:49.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.104 seconds
[2025-02-28T14:12:20.012+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:12:20.037+0000] {processor.py:186} INFO - Started process (PID=1973) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:20.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:12:20.044+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:12:20.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:20.072+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:12:20.066+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:12:20.075+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:20.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T14:12:50.689+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:12:50.698+0000] {processor.py:186} INFO - Started process (PID=1993) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:50.699+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:12:50.702+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:12:50.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:50.714+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:12:50.710+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:12:50.715+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:12:50.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T14:13:21.403+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:13:21.420+0000] {processor.py:186} INFO - Started process (PID=2013) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:21.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:13:21.426+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:13:21.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:21.448+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:13:21.442+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:13:21.451+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:21.491+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.097 seconds
[2025-02-28T14:13:52.092+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:13:52.103+0000] {processor.py:186} INFO - Started process (PID=2033) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:52.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:13:52.106+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:13:52.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:52.122+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:13:52.118+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:13:52.123+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:13:52.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T14:14:22.772+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:14:22.780+0000] {processor.py:186} INFO - Started process (PID=2053) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:22.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:14:22.784+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:14:22.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:22.796+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:14:22.793+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:14:22.797+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:22.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T14:14:53.332+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:14:53.341+0000] {processor.py:186} INFO - Started process (PID=2073) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:53.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:14:53.345+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:14:53.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:53.358+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:14:53.355+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:14:53.360+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:14:53.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T14:15:23.871+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:15:23.881+0000] {processor.py:186} INFO - Started process (PID=2093) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:23.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:15:23.885+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:15:23.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:23.898+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:15:23.894+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:15:23.900+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:23.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:15:54.456+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:15:54.464+0000] {processor.py:186} INFO - Started process (PID=2113) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:54.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:15:54.467+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:15:54.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:54.479+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:15:54.476+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:15:54.481+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:15:54.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.053 seconds
[2025-02-28T14:16:25.023+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:16:25.034+0000] {processor.py:186} INFO - Started process (PID=2133) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:25.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:16:25.038+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:16:25.038+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:25.053+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:16:25.049+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:16:25.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:25.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:16:55.598+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:16:55.611+0000] {processor.py:186} INFO - Started process (PID=2153) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:55.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:16:55.617+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:16:55.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:55.636+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:16:55.631+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:16:55.637+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:16:55.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.077 seconds
[2025-02-28T14:17:26.224+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:17:26.233+0000] {processor.py:186} INFO - Started process (PID=2173) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:26.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:17:26.237+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:17:26.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:26.248+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:17:26.245+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:17:26.250+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:26.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T14:17:56.828+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:17:56.838+0000] {processor.py:186} INFO - Started process (PID=2193) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:56.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:17:56.842+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:17:56.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:56.856+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:17:56.852+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:17:56.857+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:17:56.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T14:18:27.391+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:18:27.399+0000] {processor.py:186} INFO - Started process (PID=2213) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:27.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:18:27.403+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:18:27.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:27.417+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:18:27.413+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:18:27.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:27.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T14:18:58.087+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:18:58.096+0000] {processor.py:186} INFO - Started process (PID=2233) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:58.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:18:58.101+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:18:58.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:58.114+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:18:58.111+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:18:58.115+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:18:58.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T14:19:28.689+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:19:28.699+0000] {processor.py:186} INFO - Started process (PID=2253) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:28.700+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:19:28.703+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:19:28.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:28.715+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:19:28.712+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:19:28.717+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:28.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:19:59.384+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:19:59.394+0000] {processor.py:186} INFO - Started process (PID=2273) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:59.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:19:59.398+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:19:59.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:59.413+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:19:59.409+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:19:59.415+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:19:59.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.066 seconds
[2025-02-28T14:20:29.916+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:20:29.923+0000] {processor.py:186} INFO - Started process (PID=2293) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:20:29.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:20:29.927+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:20:29.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:20:29.940+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:20:29.936+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:20:29.941+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:20:29.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T14:21:00.444+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:21:00.458+0000] {processor.py:186} INFO - Started process (PID=2313) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:00.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:21:00.463+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:21:00.463+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:00.479+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:21:00.475+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:21:00.480+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:00.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.073 seconds
[2025-02-28T14:21:31.037+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:21:31.048+0000] {processor.py:186} INFO - Started process (PID=2333) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:31.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:21:31.056+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:21:31.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:31.071+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:21:31.068+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:21:31.073+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:21:31.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.068 seconds
[2025-02-28T14:22:01.594+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:22:01.603+0000] {processor.py:186} INFO - Started process (PID=2353) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:01.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:22:01.606+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:22:01.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:01.617+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:22:01.614+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:22:01.618+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:01.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T14:22:32.183+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:22:32.196+0000] {processor.py:186} INFO - Started process (PID=2373) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:32.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:22:32.206+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:22:32.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:32.222+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:22:32.218+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:22:32.223+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:22:32.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.071 seconds
[2025-02-28T14:23:03.031+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:23:03.041+0000] {processor.py:186} INFO - Started process (PID=2393) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:03.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:23:03.045+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:03.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:03.060+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:03.056+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:23:03.061+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:03.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.058 seconds
[2025-02-28T14:23:33.695+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:23:33.704+0000] {processor.py:186} INFO - Started process (PID=2413) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:33.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:23:33.708+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:33.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:33.721+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:33.718+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 27, in <module>
    copy_task = RedshiftDataOperator(
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/redshift_data.py", line 110, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/base_aws.py", line 96, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 959, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to RedshiftDataOperator (task_id: copy_data_from_s3). Invalid arguments were:
**kwargs: {'autocommit': True}
[2025-02-28T14:23:33.722+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:33.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T14:23:44.068+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:23:44.077+0000] {processor.py:186} INFO - Started process (PID=2433) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:44.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:23:44.082+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:44.111+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:23:44.809+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.808+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:transformed_s3_to_redshift
[2025-02-28T14:23:44.821+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.821+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:transformed_s3_to_redshift
[2025-02-28T14:23:44.830+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.829+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:transformed_s3_to_redshift
[2025-02-28T14:23:44.840+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.840+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:transformed_s3_to_redshift
[2025-02-28T14:23:44.848+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.848+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:transformed_s3_to_redshift
[2025-02-28T14:23:44.856+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.856+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:transformed_s3_to_redshift
[2025-02-28T14:23:44.864+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.863+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:transformed_s3_to_redshift
[2025-02-28T14:23:44.865+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:23:44.884+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.884+0000] {dag.py:3262} INFO - Creating ORM DAG for transformed_s3_to_redshift
[2025-02-28T14:23:44.899+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:23:44.899+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-27 00:00:00+00:00, run_after=2025-02-28 00:00:00+00:00
[2025-02-28T14:23:44.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.865 seconds
[2025-02-28T14:24:15.621+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:24:15.636+0000] {processor.py:186} INFO - Started process (PID=2459) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:15.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:24:15.640+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:15.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:15.662+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:15.707+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:15.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:24:15.745+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:15.745+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:24:15.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.156 seconds
[2025-02-28T14:24:46.139+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:24:46.148+0000] {processor.py:186} INFO - Started process (PID=2479) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:46.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:24:46.150+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:46.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:46.161+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:24:46.193+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:46.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:24:46.223+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:24:46.223+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:24:46.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.110 seconds
[2025-02-28T14:25:16.748+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:25:16.759+0000] {processor.py:186} INFO - Started process (PID=2499) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:16.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:25:16.762+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:16.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:16.777+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:16.815+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:16.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:25:16.843+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:16.843+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:25:16.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T14:25:47.330+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:25:47.340+0000] {processor.py:186} INFO - Started process (PID=2519) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:47.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:25:47.345+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:47.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:47.360+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:25:47.399+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:47.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:25:47.431+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:25:47.431+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:25:47.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T14:26:18.023+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:26:18.031+0000] {processor.py:186} INFO - Started process (PID=2539) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:18.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:26:18.035+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:18.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:18.047+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:18.080+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:18.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:26:18.110+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:18.110+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:26:18.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.113 seconds
[2025-02-28T14:26:30.197+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:26:30.210+0000] {processor.py:186} INFO - Started process (PID=2544) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:30.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:26:30.228+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:30.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:30.249+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:30.281+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:30.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:26:30.312+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:30.311+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:26:30.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.143 seconds
[2025-02-28T14:26:31.262+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:26:31.271+0000] {processor.py:186} INFO - Started process (PID=2549) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:31.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:26:31.275+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:31.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:31.293+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:26:31.326+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:31.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:26:31.358+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:26:31.358+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:26:31.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.125 seconds
[2025-02-28T14:27:01.913+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:27:01.923+0000] {processor.py:186} INFO - Started process (PID=2572) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:01.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:27:01.927+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:01.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:01.945+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:01.983+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:01.983+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:27:02.020+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:02.019+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:27:02.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.136 seconds
[2025-02-28T14:27:32.515+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:27:32.523+0000] {processor.py:186} INFO - Started process (PID=2592) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:32.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:27:32.527+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:32.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:32.542+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:27:32.574+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:32.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:27:32.603+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:27:32.603+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:27:32.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.111 seconds
[2025-02-28T14:28:03.198+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:28:03.209+0000] {processor.py:186} INFO - Started process (PID=2612) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:03.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:28:03.240+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:03.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:03.258+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:03.296+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:03.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:28:03.331+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:03.330+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:28:03.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.162 seconds
[2025-02-28T14:28:33.857+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:28:33.866+0000] {processor.py:186} INFO - Started process (PID=2632) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:33.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:28:33.870+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:33.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:33.887+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:28:33.933+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:33.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:28:33.981+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:28:33.981+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:28:34.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.151 seconds
[2025-02-28T14:29:04.496+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:29:04.506+0000] {processor.py:186} INFO - Started process (PID=2652) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:04.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:29:04.511+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:04.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:04.526+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:04.562+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:04.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:29:04.595+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:04.595+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:29:04.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T14:29:35.068+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:29:35.076+0000] {processor.py:186} INFO - Started process (PID=2672) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:35.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:29:35.079+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:35.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:35.091+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:29:35.119+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:35.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:29:35.145+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:29:35.144+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:29:35.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.105 seconds
[2025-02-28T14:30:05.738+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:30:05.746+0000] {processor.py:186} INFO - Started process (PID=2692) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:05.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:30:05.750+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:05.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:05.764+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:05.801+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:05.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:30:05.829+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:05.829+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:30:05.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T14:30:36.398+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:30:36.407+0000] {processor.py:186} INFO - Started process (PID=2712) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:36.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:30:36.410+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:36.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:36.425+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:30:36.468+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:36.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:30:36.493+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:30:36.493+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:30:36.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.115 seconds
[2025-02-28T14:31:06.962+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:31:06.985+0000] {processor.py:186} INFO - Started process (PID=2732) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:06.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:31:06.995+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:06.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:07.020+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:07.075+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:07.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:31:07.113+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:07.112+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:31:07.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.186 seconds
[2025-02-28T14:31:37.664+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:31:37.673+0000] {processor.py:186} INFO - Started process (PID=2752) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:37.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:31:37.677+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:37.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:37.697+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:31:37.740+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:37.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:31:37.771+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:31:37.771+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:31:37.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.151 seconds
[2025-02-28T14:32:08.337+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:32:08.353+0000] {processor.py:186} INFO - Started process (PID=2772) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:08.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:32:08.357+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:08.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:08.382+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:08.424+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:08.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:32:08.477+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:08.477+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:32:08.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.170 seconds
[2025-02-28T14:32:39.189+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:32:39.198+0000] {processor.py:186} INFO - Started process (PID=2792) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:39.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:32:39.202+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:39.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:39.216+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:32:39.259+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:39.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:32:39.289+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:32:39.289+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:32:39.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T14:33:09.890+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:33:09.902+0000] {processor.py:186} INFO - Started process (PID=2812) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:09.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:33:09.906+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:09.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:09.919+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:09.948+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:09.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:33:09.979+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:09.978+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:33:10.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.113 seconds
[2025-02-28T14:33:40.508+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:33:40.518+0000] {processor.py:186} INFO - Started process (PID=2832) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:40.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:33:40.521+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:40.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:40.536+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:33:40.569+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:40.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:33:40.603+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:33:40.603+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:33:40.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.121 seconds
[2025-02-28T14:34:11.094+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:34:11.104+0000] {processor.py:186} INFO - Started process (PID=2852) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:11.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:34:11.109+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:11.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:11.127+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:11.175+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:11.174+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:34:11.226+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:11.226+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:34:11.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.186 seconds
[2025-02-28T14:34:41.788+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:34:41.809+0000] {processor.py:186} INFO - Started process (PID=2872) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:41.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:34:41.814+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:41.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:41.837+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:34:41.887+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:41.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:34:41.935+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:34:41.935+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:34:41.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.187 seconds
[2025-02-28T14:35:12.390+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:35:12.399+0000] {processor.py:186} INFO - Started process (PID=2892) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:12.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:35:12.404+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:12.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:12.427+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:12.473+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:12.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:35:12.511+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:12.511+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:35:12.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.157 seconds
[2025-02-28T14:35:43.062+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:35:43.071+0000] {processor.py:186} INFO - Started process (PID=2912) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:43.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:35:43.075+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:43.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:43.090+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:35:43.130+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:43.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:35:43.160+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:35:43.160+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:35:43.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T14:36:13.823+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:36:13.832+0000] {processor.py:186} INFO - Started process (PID=2932) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:13.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:36:13.835+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:13.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:13.849+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:13.881+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:13.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:36:13.912+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:13.912+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:36:13.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.115 seconds
[2025-02-28T14:36:44.383+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:36:44.392+0000] {processor.py:186} INFO - Started process (PID=2952) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:44.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:36:44.395+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:44.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:44.410+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:36:44.445+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:44.445+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:36:44.477+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:36:44.477+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:36:44.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T14:37:15.002+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:37:15.014+0000] {processor.py:186} INFO - Started process (PID=2972) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:15.014+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:37:15.017+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:15.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:15.033+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:15.067+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:15.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:37:15.099+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:15.098+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:37:15.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T14:37:41.562+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:37:41.591+0000] {processor.py:186} INFO - Started process (PID=2992) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:41.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:37:41.597+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:41.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:41.617+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:41.869+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:41.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:37:41.892+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:41.892+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:37:41.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.358 seconds
[2025-02-28T14:37:42.642+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:37:42.650+0000] {processor.py:186} INFO - Started process (PID=2997) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:42.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:37:42.654+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:42.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:42.669+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:37:42.684+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:42.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:37:42.714+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:37:42.713+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:37:42.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.101 seconds
[2025-02-28T14:38:13.393+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:38:13.401+0000] {processor.py:186} INFO - Started process (PID=3017) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:13.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:38:13.406+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:13.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:13.421+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:13.469+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:13.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:38:13.503+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:13.503+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:38:13.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.141 seconds
[2025-02-28T14:38:43.908+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:38:43.915+0000] {processor.py:186} INFO - Started process (PID=3037) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:43.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:38:43.917+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:43.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:43.929+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:38:43.965+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:43.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:38:43.994+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:38:43.994+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:38:44.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.113 seconds
[2025-02-28T14:39:14.483+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:39:14.492+0000] {processor.py:186} INFO - Started process (PID=3057) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:14.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:39:14.496+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:14.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:14.511+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:14.546+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:14.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:39:14.576+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:14.575+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:39:14.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T14:39:45.068+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:39:45.076+0000] {processor.py:186} INFO - Started process (PID=3077) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:45.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:39:45.080+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:45.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:45.095+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:39:45.133+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:45.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:39:45.168+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:39:45.167+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:39:45.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.130 seconds
[2025-02-28T14:40:15.669+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:40:15.679+0000] {processor.py:186} INFO - Started process (PID=3097) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:15.680+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:40:15.684+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:15.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:15.708+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:15.746+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:15.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:40:15.779+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:15.778+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:40:15.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.139 seconds
[2025-02-28T14:40:46.463+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:40:46.472+0000] {processor.py:186} INFO - Started process (PID=3117) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:46.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:40:46.476+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:46.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:46.491+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:40:46.533+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:46.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:40:46.564+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:40:46.564+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:40:46.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T14:41:17.152+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:41:17.162+0000] {processor.py:186} INFO - Started process (PID=3137) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:17.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:41:17.166+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:17.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:17.183+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:17.221+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:17.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:41:17.252+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:17.252+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:41:17.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T14:41:47.763+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:41:47.771+0000] {processor.py:186} INFO - Started process (PID=3157) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:47.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:41:47.775+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:47.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:47.792+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:41:47.825+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:47.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:41:47.859+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:41:47.858+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:41:47.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T14:42:18.355+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:42:18.363+0000] {processor.py:186} INFO - Started process (PID=3177) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:18.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:42:18.366+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:18.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:18.379+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:18.413+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:18.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:42:18.440+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:18.439+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:42:18.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.105 seconds
[2025-02-28T14:42:49.049+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:42:49.058+0000] {processor.py:186} INFO - Started process (PID=3197) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:49.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:42:49.062+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:49.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:49.078+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:42:49.120+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:49.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:42:49.152+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:42:49.152+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:42:49.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T14:43:19.670+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:43:19.682+0000] {processor.py:186} INFO - Started process (PID=3217) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:19.683+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:43:19.687+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:19.687+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:19.709+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:19.763+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:19.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:43:19.810+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:19.810+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:43:19.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.180 seconds
[2025-02-28T14:43:50.168+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:43:50.177+0000] {processor.py:186} INFO - Started process (PID=3237) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:50.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:43:50.181+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:50.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:50.196+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:43:50.231+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:50.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:43:50.263+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:43:50.263+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:43:50.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.125 seconds
[2025-02-28T14:44:20.792+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:44:20.801+0000] {processor.py:186} INFO - Started process (PID=3257) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:20.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:44:20.805+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:20.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:20.819+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:20.855+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:20.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:44:20.885+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:20.884+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:44:20.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T14:44:51.444+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:44:51.452+0000] {processor.py:186} INFO - Started process (PID=3277) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:51.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:44:51.456+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:51.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:51.470+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:44:51.503+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:51.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:44:51.535+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:44:51.535+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:44:51.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T14:45:22.096+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:45:22.105+0000] {processor.py:186} INFO - Started process (PID=3297) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:22.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:45:22.109+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:22.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:22.123+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:22.157+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:22.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:45:22.185+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:22.185+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:45:22.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.113 seconds
[2025-02-28T14:45:52.713+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:45:52.721+0000] {processor.py:186} INFO - Started process (PID=3317) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:52.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:45:52.724+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:52.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:52.738+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:45:52.772+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:52.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:45:52.800+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:45:52.799+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:45:52.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T14:46:23.293+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:46:23.303+0000] {processor.py:186} INFO - Started process (PID=3337) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:23.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:46:23.306+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:23.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:23.324+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:23.358+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:23.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:46:23.385+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:23.385+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:46:23.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.115 seconds
[2025-02-28T14:46:53.897+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:46:53.906+0000] {processor.py:186} INFO - Started process (PID=3357) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:53.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:46:53.910+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:53.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:53.925+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:46:53.959+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:53.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:46:53.986+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:46:53.986+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:46:54.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.111 seconds
[2025-02-28T14:47:24.464+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:47:24.471+0000] {processor.py:186} INFO - Started process (PID=3377) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:24.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:47:24.474+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:24.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:24.486+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:24.517+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:24.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:47:24.546+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:24.546+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:47:24.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.103 seconds
[2025-02-28T14:47:55.527+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:47:55.545+0000] {processor.py:186} INFO - Started process (PID=3397) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:55.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:47:55.553+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:55.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:55.584+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:47:55.649+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:55.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:47:55.686+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:47:55.686+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:47:55.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.196 seconds
[2025-02-28T14:48:26.444+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:48:26.453+0000] {processor.py:186} INFO - Started process (PID=3417) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:26.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:48:26.456+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:26.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:26.476+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:26.508+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:26.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:48:26.540+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:26.540+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:48:26.565+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.125 seconds
[2025-02-28T14:48:57.119+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:48:57.129+0000] {processor.py:186} INFO - Started process (PID=3437) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:57.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:48:57.133+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:57.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:57.147+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:48:57.183+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:57.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:48:57.215+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:48:57.215+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:48:57.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.123 seconds
[2025-02-28T14:49:27.720+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:49:27.730+0000] {processor.py:186} INFO - Started process (PID=3457) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:27.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:49:27.733+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:27.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:27.748+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:27.787+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:27.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:49:27.818+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:27.818+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:49:27.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.123 seconds
[2025-02-28T14:49:58.307+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:49:58.316+0000] {processor.py:186} INFO - Started process (PID=3477) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:58.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:49:58.319+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:58.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:58.335+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:49:58.369+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:58.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:49:58.399+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:49:58.399+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:49:58.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T14:50:28.989+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:50:28.996+0000] {processor.py:186} INFO - Started process (PID=3497) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:28.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:50:29.000+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:29.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:29.014+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:29.045+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:29.044+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:50:29.074+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:29.073+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:50:29.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.107 seconds
[2025-02-28T14:50:59.561+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:50:59.568+0000] {processor.py:186} INFO - Started process (PID=3517) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:59.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:50:59.571+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:59.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:59.585+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:50:59.626+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:59.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:50:59.654+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:50:59.654+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:50:59.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T14:51:30.120+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:51:30.129+0000] {processor.py:186} INFO - Started process (PID=3537) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:51:30.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:51:30.133+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:51:30.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:51:30.148+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:51:30.182+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:51:30.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:51:30.213+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:51:30.213+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:51:30.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T14:52:00.754+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:52:00.764+0000] {processor.py:186} INFO - Started process (PID=3557) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:00.765+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:52:00.769+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:00.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:00.786+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:00.822+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:00.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:52:00.852+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:00.851+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:52:00.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T14:52:31.336+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:52:31.347+0000] {processor.py:186} INFO - Started process (PID=3577) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:31.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:52:31.351+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:31.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:31.367+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:52:31.400+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:31.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:52:31.428+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:52:31.428+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:52:31.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.118 seconds
[2025-02-28T14:53:01.932+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:53:01.940+0000] {processor.py:186} INFO - Started process (PID=3597) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:01.940+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:53:01.943+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:01.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:01.954+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:01.980+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:01.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:53:02.004+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:02.004+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:53:02.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.092 seconds
[2025-02-28T14:53:32.503+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:53:32.512+0000] {processor.py:186} INFO - Started process (PID=3617) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:32.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:53:32.517+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:32.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:32.532+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:53:32.574+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:32.573+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:53:32.608+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:53:32.607+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:53:32.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T14:54:03.283+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:54:03.293+0000] {processor.py:186} INFO - Started process (PID=3637) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:03.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:54:03.297+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:03.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:03.314+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:03.350+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:03.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:54:03.393+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:03.393+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:54:03.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.138 seconds
[2025-02-28T14:54:34.103+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:54:34.111+0000] {processor.py:186} INFO - Started process (PID=3657) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:34.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:54:34.115+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:34.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:34.130+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:54:34.171+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:34.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:54:34.202+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:54:34.202+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:54:34.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.151 seconds
[2025-02-28T14:55:04.759+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:55:04.770+0000] {processor.py:186} INFO - Started process (PID=3677) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:04.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:55:04.775+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:04.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:04.797+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:04.844+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:04.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:55:04.893+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:04.892+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:55:04.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.164 seconds
[2025-02-28T14:55:35.331+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:55:35.340+0000] {processor.py:186} INFO - Started process (PID=3697) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:35.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:55:35.353+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:35.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:35.370+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:55:35.410+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:35.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:55:35.445+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:55:35.445+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:55:35.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.155 seconds
[2025-02-28T14:56:06.075+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:56:06.083+0000] {processor.py:186} INFO - Started process (PID=3717) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:06.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:56:06.088+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:06.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:06.102+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:06.138+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:06.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:56:06.166+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:06.166+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:56:06.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T14:56:36.659+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:56:36.668+0000] {processor.py:186} INFO - Started process (PID=3737) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:36.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:56:36.672+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:36.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:36.686+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:56:36.727+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:36.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:56:36.759+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:56:36.759+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:56:36.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T14:57:07.351+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:57:07.360+0000] {processor.py:186} INFO - Started process (PID=3757) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:07.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:57:07.364+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:07.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:07.378+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:07.414+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:07.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:57:07.442+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:07.442+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:57:07.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T14:57:38.005+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:57:38.014+0000] {processor.py:186} INFO - Started process (PID=3777) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:38.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:57:38.018+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:38.017+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:38.031+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:57:38.066+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:38.066+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:57:38.095+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:57:38.095+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:57:38.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.113 seconds
[2025-02-28T14:58:08.637+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:58:08.650+0000] {processor.py:186} INFO - Started process (PID=3797) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:08.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:58:08.656+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:08.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:08.673+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:08.707+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:08.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:58:08.737+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:08.736+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:58:08.763+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.131 seconds
[2025-02-28T14:58:39.258+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:58:39.265+0000] {processor.py:186} INFO - Started process (PID=3817) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:39.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:58:39.269+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:39.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:39.281+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:58:39.319+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:39.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:58:39.348+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:58:39.348+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:58:39.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.115 seconds
[2025-02-28T14:59:09.831+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:59:09.840+0000] {processor.py:186} INFO - Started process (PID=3837) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:09.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:59:09.844+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:09.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:09.858+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:09.892+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:09.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:59:09.919+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:09.919+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:59:09.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.111 seconds
[2025-02-28T14:59:40.387+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T14:59:40.395+0000] {processor.py:186} INFO - Started process (PID=3857) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:40.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T14:59:40.399+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:40.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:40.413+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T14:59:40.452+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:40.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T14:59:40.482+0000] {logging_mixin.py:190} INFO - [2025-02-28T14:59:40.481+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T14:59:40.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T15:00:10.967+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:00:10.975+0000] {processor.py:186} INFO - Started process (PID=3877) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:10.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:00:10.979+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:10.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:10.993+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:11.031+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:11.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:00:11.060+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:11.060+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:00:11.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.118 seconds
[2025-02-28T15:00:41.539+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:00:41.549+0000] {processor.py:186} INFO - Started process (PID=3897) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:41.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:00:41.553+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:41.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:41.567+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:00:41.602+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:41.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:00:41.630+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:00:41.630+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:00:41.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.115 seconds
[2025-02-28T15:01:12.127+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:01:12.135+0000] {processor.py:186} INFO - Started process (PID=3917) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:12.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:01:12.139+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:12.139+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:12.153+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:12.190+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:12.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:01:12.219+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:12.219+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:01:12.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T15:01:42.780+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:01:42.788+0000] {processor.py:186} INFO - Started process (PID=3937) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:42.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:01:42.792+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:42.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:42.810+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:01:42.849+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:42.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:01:42.880+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:01:42.880+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:01:42.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.126 seconds
[2025-02-28T15:02:13.419+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:02:13.429+0000] {processor.py:186} INFO - Started process (PID=3957) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:13.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:02:13.434+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:13.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:13.452+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:13.493+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:13.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:02:13.533+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:13.533+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:02:13.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.149 seconds
[2025-02-28T15:02:44.069+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:02:44.076+0000] {processor.py:186} INFO - Started process (PID=3977) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:44.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:02:44.080+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:44.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:44.094+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:02:44.130+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:44.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:02:44.157+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:02:44.156+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:02:44.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.108 seconds
[2025-02-28T15:03:14.702+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:03:14.711+0000] {processor.py:186} INFO - Started process (PID=3997) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:14.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:03:14.715+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:14.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:14.731+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:14.769+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:14.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:03:14.800+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:14.799+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:03:14.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T15:03:45.050+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:03:45.059+0000] {processor.py:186} INFO - Started process (PID=4017) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:45.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:03:45.062+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:45.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:45.075+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:03:45.107+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:45.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:03:45.135+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:03:45.134+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:03:45.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.105 seconds
[2025-02-28T15:04:15.641+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:04:15.649+0000] {processor.py:186} INFO - Started process (PID=4037) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:15.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:04:15.652+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:15.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:15.665+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:15.701+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:15.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:04:15.747+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:15.747+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:04:15.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.138 seconds
[2025-02-28T15:04:46.282+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:04:46.297+0000] {processor.py:186} INFO - Started process (PID=4057) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:46.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:04:46.303+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:46.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:46.327+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:04:46.376+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:46.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:04:46.417+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:04:46.417+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:04:46.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.176 seconds
[2025-02-28T15:05:16.778+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:05:16.789+0000] {processor.py:186} INFO - Started process (PID=4077) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:16.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:05:16.793+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:16.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:16.807+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:16.849+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:16.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:05:16.882+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:16.881+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:05:16.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.134 seconds
[2025-02-28T15:05:47.419+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:05:47.428+0000] {processor.py:186} INFO - Started process (PID=4097) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:47.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:05:47.431+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:47.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:47.446+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:05:47.482+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:47.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:05:47.510+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:05:47.510+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:05:47.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T15:06:18.045+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:06:18.054+0000] {processor.py:186} INFO - Started process (PID=4117) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:18.055+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:06:18.057+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:18.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:18.070+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:18.098+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:18.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:06:18.120+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:18.120+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:06:18.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.096 seconds
[2025-02-28T15:06:48.584+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:06:48.593+0000] {processor.py:186} INFO - Started process (PID=4137) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:48.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:06:48.597+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:48.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:48.611+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:06:48.650+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:48.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:06:48.686+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:06:48.686+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:06:48.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T15:07:19.184+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:07:19.193+0000] {processor.py:186} INFO - Started process (PID=4157) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:19.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:07:19.198+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:19.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:19.219+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:19.254+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:19.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:07:19.285+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:19.285+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:07:19.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T15:07:49.875+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:07:49.884+0000] {processor.py:186} INFO - Started process (PID=4177) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:49.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:07:49.887+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:49.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:49.900+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:07:49.931+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:49.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:07:49.961+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:07:49.961+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:07:49.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T15:08:20.530+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:08:20.539+0000] {processor.py:186} INFO - Started process (PID=4197) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:20.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:08:20.543+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:20.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:20.558+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:20.591+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:20.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:08:20.623+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:20.623+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:08:20.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T15:08:51.134+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:08:51.142+0000] {processor.py:186} INFO - Started process (PID=4217) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:51.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:08:51.146+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:51.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:51.163+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:08:51.198+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:51.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:08:51.229+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:08:51.228+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:08:51.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T15:09:21.910+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:09:21.920+0000] {processor.py:186} INFO - Started process (PID=4237) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:21.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:09:21.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:21.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:21.937+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:21.973+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:21.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:09:22.008+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:22.008+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:09:22.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.126 seconds
[2025-02-28T15:09:52.560+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:09:52.570+0000] {processor.py:186} INFO - Started process (PID=4257) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:52.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:09:52.573+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:52.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:52.588+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:09:52.623+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:52.623+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:09:52.657+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:09:52.657+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:09:52.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.126 seconds
[2025-02-28T15:10:23.189+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:10:23.198+0000] {processor.py:186} INFO - Started process (PID=4277) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:23.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:10:23.201+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:23.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:23.218+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:23.258+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:23.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:10:23.291+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:23.291+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:10:23.316+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.130 seconds
[2025-02-28T15:10:53.935+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:10:53.945+0000] {processor.py:186} INFO - Started process (PID=4297) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:53.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:10:53.949+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:53.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:53.963+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:10:53.997+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:53.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:10:54.027+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:10:54.027+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:10:54.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.118 seconds
[2025-02-28T15:11:24.532+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:11:24.541+0000] {processor.py:186} INFO - Started process (PID=4317) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:24.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:11:24.545+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:24.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:24.559+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:24.592+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:24.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:11:24.621+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:24.620+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:11:24.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T15:11:55.137+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:11:55.146+0000] {processor.py:186} INFO - Started process (PID=4337) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:55.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:11:55.149+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:55.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:55.163+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:11:55.198+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:55.197+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:11:55.227+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:11:55.226+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:11:55.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T15:12:25.823+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:12:25.832+0000] {processor.py:186} INFO - Started process (PID=4357) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:25.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:12:25.835+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:25.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:25.850+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:25.885+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:25.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:12:25.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:25.923+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:12:25.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.129 seconds
[2025-02-28T15:12:56.401+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:12:56.409+0000] {processor.py:186} INFO - Started process (PID=4377) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:56.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:12:56.413+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:56.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:56.428+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:12:56.461+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:56.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:12:56.491+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:12:56.491+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:12:56.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T15:13:27.013+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:13:27.023+0000] {processor.py:186} INFO - Started process (PID=4397) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:27.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:13:27.027+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:27.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:27.064+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:27.122+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:27.121+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:13:27.157+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:27.157+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:13:27.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.176 seconds
[2025-02-28T15:13:57.820+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:13:57.830+0000] {processor.py:186} INFO - Started process (PID=4417) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:57.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:13:57.835+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:57.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:57.850+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:13:57.885+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:57.885+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:13:57.925+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:13:57.925+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:13:57.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.133 seconds
[2025-02-28T15:14:28.497+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:14:28.506+0000] {processor.py:186} INFO - Started process (PID=4437) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:28.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:14:28.510+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:28.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:28.524+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:28.562+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:28.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:14:28.592+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:28.592+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:14:28.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T15:14:59.139+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:14:59.146+0000] {processor.py:186} INFO - Started process (PID=4457) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:59.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:14:59.148+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:59.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:59.160+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:14:59.192+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:59.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:14:59.225+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:14:59.225+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:14:59.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.109 seconds
[2025-02-28T15:15:29.806+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:15:29.815+0000] {processor.py:186} INFO - Started process (PID=4477) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:15:29.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:15:29.818+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:15:29.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:15:29.832+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:15:29.866+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:15:29.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:15:29.894+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:15:29.894+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:15:29.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T15:16:00.371+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:16:00.379+0000] {processor.py:186} INFO - Started process (PID=4497) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:00.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:16:00.382+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:00.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:00.394+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:00.428+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:00.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:16:00.452+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:00.451+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:16:00.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.101 seconds
[2025-02-28T15:16:31.096+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:16:31.105+0000] {processor.py:186} INFO - Started process (PID=4517) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:31.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:16:31.109+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:31.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:31.123+0000] {processor.py:925} INFO - DAG(s) 'transformed_s3_to_redshift' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:31.156+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:31.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:16:31.193+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:31.192+0000] {dag.py:4180} INFO - Setting next_dagrun for transformed_s3_to_redshift to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:16:31.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.123 seconds
[2025-02-28T15:16:52.871+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:16:52.880+0000] {processor.py:186} INFO - Started process (PID=4537) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:52.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:16:52.884+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:52.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:52.900+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:52.893+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:16:52.901+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:52.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.063 seconds
[2025-02-28T15:16:53.897+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:16:53.906+0000] {processor.py:186} INFO - Started process (PID=4542) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:53.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:16:53.910+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:53.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:53.921+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:53.919+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:16:53.922+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:53.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.053 seconds
[2025-02-28T15:16:55.015+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:16:55.029+0000] {processor.py:186} INFO - Started process (PID=4547) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:55.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:16:55.040+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:55.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:55.059+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:16:55.056+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:16:55.060+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:16:55.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T15:17:25.750+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:17:25.795+0000] {processor.py:186} INFO - Started process (PID=4567) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:25.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:17:25.805+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:17:25.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:25.817+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:17:25.814+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:17:25.844+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:25.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.217 seconds
[2025-02-28T15:17:56.878+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:17:56.890+0000] {processor.py:186} INFO - Started process (PID=4587) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:56.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:17:56.894+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:17:56.894+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:56.904+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:17:56.899+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:17:56.907+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:17:56.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.068 seconds
[2025-02-28T15:18:27.433+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:18:27.442+0000] {processor.py:186} INFO - Started process (PID=4607) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:27.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:18:27.445+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:18:27.444+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:27.453+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:18:27.450+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:18:27.454+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:27.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:18:58.215+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:18:58.224+0000] {processor.py:186} INFO - Started process (PID=4627) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:58.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:18:58.227+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:18:58.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:58.235+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:18:58.232+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:18:58.237+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:18:58.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:19:28.677+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:19:28.686+0000] {processor.py:186} INFO - Started process (PID=4647) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:28.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:19:28.689+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:19:28.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:28.696+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:19:28.694+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:19:28.697+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:28.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.048 seconds
[2025-02-28T15:19:59.300+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:19:59.310+0000] {processor.py:186} INFO - Started process (PID=4667) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:59.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:19:59.312+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:19:59.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:59.319+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:19:59.317+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:19:59.321+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:19:59.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T15:20:29.839+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:20:29.851+0000] {processor.py:186} INFO - Started process (PID=4687) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:20:29.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:20:29.854+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:20:29.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:20:29.864+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:20:29.860+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:20:29.866+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:20:29.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.061 seconds
[2025-02-28T15:21:00.316+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:21:00.322+0000] {processor.py:186} INFO - Started process (PID=4707) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:00.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:21:00.325+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:21:00.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:00.330+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:21:00.328+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:21:00.331+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:00.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.035 seconds
[2025-02-28T15:21:30.911+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:21:30.921+0000] {processor.py:186} INFO - Started process (PID=4732) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:30.921+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:21:30.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:21:30.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:30.930+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:21:30.928+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:21:30.931+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:21:30.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.049 seconds
[2025-02-28T15:22:01.441+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:22:01.450+0000] {processor.py:186} INFO - Started process (PID=4752) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:01.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:22:01.452+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:22:01.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:01.459+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:22:01.456+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:22:01.460+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:01.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.048 seconds
[2025-02-28T15:22:31.972+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:22:31.982+0000] {processor.py:186} INFO - Started process (PID=4772) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:31.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:22:31.985+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:22:31.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:31.992+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:22:31.990+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:22:31.994+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:22:32.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T15:23:02.513+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:23:02.522+0000] {processor.py:186} INFO - Started process (PID=4792) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:02.522+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:23:02.525+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:23:02.524+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:02.532+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:23:02.529+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:23:02.533+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:02.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.046 seconds
[2025-02-28T15:23:33.021+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:23:33.030+0000] {processor.py:186} INFO - Started process (PID=4812) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:33.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:23:33.033+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:23:33.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:33.041+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:23:33.038+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:23:33.042+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:23:33.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T15:24:03.544+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:24:03.553+0000] {processor.py:186} INFO - Started process (PID=4832) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:03.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:24:03.555+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:24:03.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:03.563+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:24:03.560+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:24:03.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:03.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.047 seconds
[2025-02-28T15:24:34.142+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:24:34.152+0000] {processor.py:186} INFO - Started process (PID=4852) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:34.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:24:34.154+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:24:34.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:34.163+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:24:34.160+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:24:34.165+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:24:34.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T15:25:04.715+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:25:04.724+0000] {processor.py:186} INFO - Started process (PID=4872) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:04.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:25:04.726+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:25:04.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:04.734+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:25:04.731+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:25:04.736+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:04.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.049 seconds
[2025-02-28T15:25:35.236+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:25:35.246+0000] {processor.py:186} INFO - Started process (PID=4892) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:35.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:25:35.248+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:25:35.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:35.255+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:25:35.252+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:25:35.257+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:25:35.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.048 seconds
[2025-02-28T15:26:05.742+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:26:05.751+0000] {processor.py:186} INFO - Started process (PID=4912) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:26:05.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:26:05.754+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:26:05.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:26:05.761+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:26:05.758+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:26:05.762+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:26:05.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.047 seconds
[2025-02-28T15:27:00.349+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:27:00.364+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:00.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:27:00.378+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:27:00.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:00.387+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:27:00.384+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:27:00.389+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:00.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.077 seconds
[2025-02-28T15:27:31.002+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:27:31.017+0000] {processor.py:186} INFO - Started process (PID=194) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:31.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:27:31.023+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:27:31.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:31.039+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:27:31.034+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:27:31.040+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:27:31.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.072 seconds
[2025-02-28T15:28:01.802+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:28:01.813+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:01.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:28:01.817+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:28:01.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:01.826+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:28:01.822+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:28:01.828+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:01.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.062 seconds
[2025-02-28T15:28:32.466+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:28:32.474+0000] {processor.py:186} INFO - Started process (PID=234) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:32.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:28:32.484+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:28:32.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:32.491+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:28:32.489+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import AwsGlueCrawlerOperator
ImportError: cannot import name 'AwsGlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:28:32.493+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:28:32.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.060 seconds
[2025-02-28T15:29:01.104+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:29:01.114+0000] {processor.py:186} INFO - Started process (PID=251) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:01.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:29:01.118+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:01.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:01.132+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:01.127+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:29:01.134+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:01.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.076 seconds
[2025-02-28T15:29:02.118+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:29:02.128+0000] {processor.py:186} INFO - Started process (PID=256) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:02.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:29:02.134+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:02.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:02.149+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:02.145+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:29:02.151+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:02.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.069 seconds
[2025-02-28T15:29:32.662+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:29:32.669+0000] {processor.py:186} INFO - Started process (PID=276) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:32.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:29:32.672+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:32.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:32.679+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:29:32.676+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:29:32.680+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:29:32.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.042 seconds
[2025-02-28T15:30:03.273+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:30:03.283+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:03.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:30:03.287+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:30:03.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:03.295+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:30:03.292+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:30:03.299+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:03.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.053 seconds
[2025-02-28T15:30:33.872+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:30:33.882+0000] {processor.py:186} INFO - Started process (PID=316) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:33.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:30:33.886+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:30:33.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:33.898+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:30:33.891+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:30:33.902+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:30:33.943+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.075 seconds
[2025-02-28T15:31:04.441+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:31:04.451+0000] {processor.py:186} INFO - Started process (PID=336) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:04.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:31:04.454+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:31:04.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:04.462+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:31:04.459+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:31:04.463+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:04.482+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.045 seconds
[2025-02-28T15:31:35.134+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:31:35.144+0000] {processor.py:186} INFO - Started process (PID=356) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:35.144+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:31:35.148+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:31:35.147+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:35.155+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:31:35.152+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:31:35.157+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:31:35.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:32:05.897+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:32:05.908+0000] {processor.py:186} INFO - Started process (PID=376) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:05.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:32:05.912+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:32:05.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:05.921+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:32:05.917+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:32:05.923+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:05.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T15:32:36.318+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:32:36.332+0000] {processor.py:186} INFO - Started process (PID=396) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:36.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:32:36.338+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:32:36.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:36.393+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:32:36.373+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:32:36.410+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:32:36.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.134 seconds
[2025-02-28T15:33:07.031+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:33:07.041+0000] {processor.py:186} INFO - Started process (PID=416) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:07.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:33:07.044+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:33:07.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:07.053+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:33:07.049+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:33:07.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:07.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.059 seconds
[2025-02-28T15:33:37.654+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:33:37.663+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:37.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:33:37.667+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:33:37.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:37.676+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:33:37.672+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:33:37.678+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:33:37.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.057 seconds
[2025-02-28T15:34:08.124+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:08.135+0000] {processor.py:186} INFO - Started process (PID=456) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:08.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:08.140+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:08.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:08.149+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:08.146+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:08.152+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:08.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.062 seconds
[2025-02-28T15:34:38.854+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:38.863+0000] {processor.py:186} INFO - Started process (PID=476) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:38.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:38.867+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:38.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:38.875+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:38.872+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerOperator
ImportError: cannot import name 'GlueCrawlerOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:38.877+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:38.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:34:41.034+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:41.043+0000] {processor.py:186} INFO - Started process (PID=491) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.046+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:41.049+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:41.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.064+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:41.061+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:41.066+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.062 seconds
[2025-02-28T15:34:41.520+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:41.528+0000] {processor.py:186} INFO - Started process (PID=501) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:41.532+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:41.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.544+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:41.542+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:41.546+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:41.572+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.056 seconds
[2025-02-28T15:34:42.536+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:42.545+0000] {processor.py:186} INFO - Started process (PID=506) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:42.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:42.548+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:42.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:42.556+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:42.554+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:42.557+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:42.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.049 seconds
[2025-02-28T15:34:43.552+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:43.561+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:43.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:43.564+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:43.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:43.575+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:43.573+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:43.576+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:43.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T15:34:44.632+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:44.641+0000] {processor.py:186} INFO - Started process (PID=516) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:44.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:44.645+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:44.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:44.656+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:44.654+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:44.657+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:44.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.055 seconds
[2025-02-28T15:34:45.660+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:34:45.670+0000] {processor.py:186} INFO - Started process (PID=521) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:45.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:34:45.675+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:45.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:45.684+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:34:45.681+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:34:45.686+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:34:45.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.067 seconds
[2025-02-28T15:35:16.205+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:35:16.215+0000] {processor.py:186} INFO - Started process (PID=541) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:16.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:35:16.220+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:35:16.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:16.227+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:35:16.225+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:35:16.229+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:16.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.053 seconds
[2025-02-28T15:35:46.666+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:35:46.674+0000] {processor.py:186} INFO - Started process (PID=561) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:46.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:35:46.677+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:35:46.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:46.684+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:35:46.682+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:35:46.685+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:35:46.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.054 seconds
[2025-02-28T15:36:17.147+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:36:17.158+0000] {processor.py:186} INFO - Started process (PID=581) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:17.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:36:17.163+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:36:17.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:17.171+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:36:17.168+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:36:17.173+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:17.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.062 seconds
[2025-02-28T15:36:47.868+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:36:47.877+0000] {processor.py:186} INFO - Started process (PID=601) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:47.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:36:47.881+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:36:47.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:47.888+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:36:47.885+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:36:47.889+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:36:47.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.049 seconds
[2025-02-28T15:37:18.542+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:37:18.552+0000] {processor.py:186} INFO - Started process (PID=621) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:18.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:37:18.555+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:37:18.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:18.563+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:37:18.560+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:37:18.564+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:18.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.053 seconds
[2025-02-28T15:37:49.344+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:37:49.352+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:49.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:37:49.356+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:37:49.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:49.364+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:37:49.361+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:37:49.365+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:37:49.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:38:19.856+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:38:19.865+0000] {processor.py:186} INFO - Started process (PID=661) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:19.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:38:19.869+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:38:19.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:19.877+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:38:19.874+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:38:19.879+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:19.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.051 seconds
[2025-02-28T15:38:50.338+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:38:50.347+0000] {processor.py:186} INFO - Started process (PID=681) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:50.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:38:50.350+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:38:50.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:50.358+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:38:50.355+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:38:50.359+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:38:50.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.049 seconds
[2025-02-28T15:39:20.885+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:39:20.903+0000] {processor.py:186} INFO - Started process (PID=701) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:20.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:39:20.912+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:39:20.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:20.925+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:39:20.920+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:39:20.929+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:20.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.088 seconds
[2025-02-28T15:39:51.578+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:39:51.590+0000] {processor.py:186} INFO - Started process (PID=721) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:51.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:39:51.596+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:39:51.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:51.606+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:39:51.603+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:39:51.607+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:39:51.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.066 seconds
[2025-02-28T15:40:22.201+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:40:22.211+0000] {processor.py:186} INFO - Started process (PID=741) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:22.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:40:22.215+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:40:22.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:22.223+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:40:22.220+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:40:22.225+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:22.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.052 seconds
[2025-02-28T15:40:52.671+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:40:52.678+0000] {processor.py:186} INFO - Started process (PID=761) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:52.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:40:52.681+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:40:52.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:52.687+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:40:52.685+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:40:52.687+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:40:52.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.041 seconds
[2025-02-28T15:41:23.119+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:41:23.128+0000] {processor.py:186} INFO - Started process (PID=781) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:23.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:41:23.131+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:23.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:23.138+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:23.136+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/transformed_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/transformed_data_dag.py", line 2, in <module>
    from airflow.providers.amazon.aws.operators.glue import GlueCrawlerStartOperator
ImportError: cannot import name 'GlueCrawlerStartOperator' from 'airflow.providers.amazon.aws.operators.glue' (/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/amazon/aws/operators/glue.py)
[2025-02-28T15:41:23.139+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:23.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.048 seconds
[2025-02-28T15:41:51.624+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:41:51.634+0000] {processor.py:186} INFO - Started process (PID=799) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:51.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:41:51.637+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:51.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:51.660+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:41:52.158+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.157+0000] {override.py:1912} INFO - Created Permission View: can read on DAG:s3_to_redshift_using_glue
[2025-02-28T15:41:52.171+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.170+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG:s3_to_redshift_using_glue
[2025-02-28T15:41:52.178+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.178+0000] {override.py:1912} INFO - Created Permission View: can edit on DAG:s3_to_redshift_using_glue
[2025-02-28T15:41:52.186+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.185+0000] {override.py:1912} INFO - Created Permission View: can read on DAG Run:s3_to_redshift_using_glue
[2025-02-28T15:41:52.193+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.192+0000] {override.py:1912} INFO - Created Permission View: menu access on DAG Run:s3_to_redshift_using_glue
[2025-02-28T15:41:52.200+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.200+0000] {override.py:1912} INFO - Created Permission View: can delete on DAG Run:s3_to_redshift_using_glue
[2025-02-28T15:41:52.207+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.207+0000] {override.py:1912} INFO - Created Permission View: can create on DAG Run:s3_to_redshift_using_glue
[2025-02-28T15:41:52.208+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:41:52.223+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.223+0000] {dag.py:3262} INFO - Creating ORM DAG for s3_to_redshift_using_glue
[2025-02-28T15:41:52.235+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:41:52.235+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-27 00:00:00+00:00, run_after=2025-02-28 00:00:00+00:00
[2025-02-28T15:41:52.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.634 seconds
[2025-02-28T15:42:00.251+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:42:00.265+0000] {processor.py:186} INFO - Started process (PID=806) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:00.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:42:00.270+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:00.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:00.297+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:00.323+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:00.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:42:00.365+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:00.365+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-27 00:00:00+00:00, run_after=2025-02-28 00:00:00+00:00
[2025-02-28T15:42:00.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.146 seconds
[2025-02-28T15:42:30.772+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:42:30.781+0000] {processor.py:186} INFO - Started process (PID=832) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:30.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:42:30.786+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:30.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:30.804+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:42:30.840+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:30.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:42:30.878+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:42:30.878+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:42:30.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.137 seconds
[2025-02-28T15:43:01.544+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:43:01.553+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:01.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:43:01.557+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:01.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:01.573+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:01.609+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:01.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:43:01.643+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:01.642+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:43:01.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T15:43:31.844+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:43:31.855+0000] {processor.py:186} INFO - Started process (PID=872) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:31.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:43:31.860+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:31.860+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:31.878+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:43:31.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:31.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:43:31.963+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:43:31.962+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:43:31.992+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.151 seconds
[2025-02-28T15:44:02.649+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:44:02.658+0000] {processor.py:186} INFO - Started process (PID=892) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:02.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:44:02.662+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:02.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:02.677+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:02.709+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:02.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:44:02.756+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:02.756+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:44:02.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.141 seconds
[2025-02-28T15:44:33.336+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:44:33.346+0000] {processor.py:186} INFO - Started process (PID=912) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:33.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:44:33.350+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:33.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:33.370+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:44:33.409+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:33.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:44:33.448+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:44:33.448+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:44:33.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.150 seconds
[2025-02-28T15:45:03.576+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:45:03.585+0000] {processor.py:186} INFO - Started process (PID=935) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:03.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:45:03.588+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:03.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:03.604+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:03.638+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:03.638+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:45:03.675+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:03.675+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:45:03.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.322 seconds
[2025-02-28T15:45:34.549+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:45:34.559+0000] {processor.py:186} INFO - Started process (PID=955) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:34.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:45:34.563+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:34.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:34.579+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:45:34.615+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:34.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:45:34.654+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:45:34.654+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:45:34.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.134 seconds
[2025-02-28T15:46:05.322+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:46:05.331+0000] {processor.py:186} INFO - Started process (PID=975) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:05.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:46:05.336+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:05.335+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:05.352+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:05.387+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:05.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:46:05.423+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:05.423+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:46:05.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.129 seconds
[2025-02-28T15:46:35.911+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:46:35.920+0000] {processor.py:186} INFO - Started process (PID=995) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:35.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:46:35.925+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:35.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:35.943+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:46:35.981+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:35.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:46:36.023+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:46:36.022+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:46:36.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.143 seconds
[2025-02-28T15:47:06.351+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:47:06.368+0000] {processor.py:186} INFO - Started process (PID=1015) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:06.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:47:06.375+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:06.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:06.396+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:06.436+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:06.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:47:06.479+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:06.479+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:47:06.508+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.165 seconds
[2025-02-28T15:47:36.777+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:47:36.787+0000] {processor.py:186} INFO - Started process (PID=1035) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:36.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:47:36.791+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:36.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:36.809+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:47:36.844+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:36.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:47:36.880+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:47:36.880+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:47:36.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T15:48:07.532+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:48:07.541+0000] {processor.py:186} INFO - Started process (PID=1058) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:07.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:48:07.546+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:07.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:07.563+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:07.603+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:07.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:48:07.645+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:07.644+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:48:07.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.143 seconds
[2025-02-28T15:48:38.125+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:48:38.134+0000] {processor.py:186} INFO - Started process (PID=1078) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:38.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:48:38.138+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:38.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:38.153+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:48:38.183+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:38.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:48:38.211+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:48:38.211+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:48:38.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.106 seconds
[2025-02-28T15:49:08.645+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:49:08.653+0000] {processor.py:186} INFO - Started process (PID=1098) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:08.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:49:08.657+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:08.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:08.672+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:08.703+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:08.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:49:08.739+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:08.739+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:49:08.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T15:49:39.047+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:49:39.057+0000] {processor.py:186} INFO - Started process (PID=1118) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:39.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:49:39.061+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:39.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:39.077+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:49:39.107+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:39.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:49:39.137+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:49:39.137+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:49:39.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T15:50:09.578+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:50:09.586+0000] {processor.py:186} INFO - Started process (PID=1138) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:09.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:50:09.590+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:09.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:09.606+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:09.638+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:09.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:50:09.675+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:09.675+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:50:09.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T15:50:40.188+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:50:40.195+0000] {processor.py:186} INFO - Started process (PID=1158) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:40.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:50:40.198+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:40.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:40.210+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:50:40.240+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:40.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:50:40.273+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:50:40.273+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:50:40.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.289 seconds
[2025-02-28T15:51:10.798+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:51:10.807+0000] {processor.py:186} INFO - Started process (PID=1178) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:10.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:51:10.815+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:10.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:10.841+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:10.918+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:10.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:51:11.015+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:11.014+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:51:11.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.300 seconds
[2025-02-28T15:51:41.397+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:51:41.406+0000] {processor.py:186} INFO - Started process (PID=1198) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:41.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:51:41.410+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:41.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:41.426+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:51:41.458+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:41.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:51:41.492+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:51:41.491+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:51:41.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T15:52:12.130+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:52:12.141+0000] {processor.py:186} INFO - Started process (PID=1218) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:12.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:52:12.145+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:12.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:12.164+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:12.203+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:12.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:52:12.242+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:12.242+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:52:12.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.144 seconds
[2025-02-28T15:52:42.925+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:52:42.936+0000] {processor.py:186} INFO - Started process (PID=1238) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:42.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:52:42.940+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:42.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:42.957+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:52:43.000+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:43.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:52:43.041+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:52:43.040+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:52:43.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.146 seconds
[2025-02-28T15:53:13.692+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:53:13.703+0000] {processor.py:186} INFO - Started process (PID=1258) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:13.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:53:13.707+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:13.706+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:13.724+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:13.775+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:13.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:53:13.814+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:13.813+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:53:13.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.153 seconds
[2025-02-28T15:53:43.914+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:53:43.925+0000] {processor.py:186} INFO - Started process (PID=1278) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:43.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:53:43.929+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:43.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:43.946+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:53:43.991+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:43.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:53:44.225+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:53:44.224+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:53:44.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.345 seconds
[2025-02-28T15:54:14.754+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:54:14.778+0000] {processor.py:186} INFO - Started process (PID=1298) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:14.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:54:14.784+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:14.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:14.801+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:14.839+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:14.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:54:14.881+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:14.880+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:54:14.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.165 seconds
[2025-02-28T15:54:45.376+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:54:45.395+0000] {processor.py:186} INFO - Started process (PID=1318) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:45.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:54:45.402+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:45.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:45.428+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:54:45.499+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:45.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:54:45.561+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:54:45.561+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:54:45.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.236 seconds
[2025-02-28T15:55:16.056+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:55:16.066+0000] {processor.py:186} INFO - Started process (PID=1338) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:16.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:55:16.070+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:16.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:16.090+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:16.126+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:16.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:55:16.165+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:16.165+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:55:16.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.140 seconds
[2025-02-28T15:55:46.707+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:55:46.716+0000] {processor.py:186} INFO - Started process (PID=1358) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:46.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:55:46.723+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:46.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:46.740+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:55:46.777+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:46.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:55:46.815+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:55:46.815+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:55:46.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.144 seconds
[2025-02-28T15:56:16.984+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:56:16.996+0000] {processor.py:186} INFO - Started process (PID=1378) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:16.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:56:17.001+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:17.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:17.030+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:17.080+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:17.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:56:17.132+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:17.132+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:56:17.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.388 seconds
[2025-02-28T15:56:47.571+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:56:47.580+0000] {processor.py:186} INFO - Started process (PID=1393) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:47.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:56:47.588+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:47.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:47.607+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:56:47.641+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:47.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:56:47.678+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:56:47.678+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:56:47.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.135 seconds
[2025-02-28T15:57:18.192+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:57:18.202+0000] {processor.py:186} INFO - Started process (PID=1413) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:18.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:57:18.209+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:18.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:18.230+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:18.271+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:18.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:57:18.310+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:18.310+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:57:18.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.151 seconds
[2025-02-28T15:57:48.819+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:57:48.829+0000] {processor.py:186} INFO - Started process (PID=1433) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:48.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:57:48.833+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:48.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:48.852+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:57:48.887+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:48.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:57:48.925+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:57:48.925+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:57:48.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.148 seconds
[2025-02-28T15:58:19.077+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:58:19.113+0000] {processor.py:186} INFO - Started process (PID=1453) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:19.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:58:19.120+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:19.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:19.137+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:19.172+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:19.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:58:19.212+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:19.211+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:58:19.238+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.165 seconds
[2025-02-28T15:58:49.583+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:58:49.593+0000] {processor.py:186} INFO - Started process (PID=1473) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:49.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:58:49.597+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:49.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:49.614+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:58:49.666+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:49.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:58:49.706+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:58:49.706+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:58:49.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.150 seconds
[2025-02-28T15:59:20.306+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:59:20.314+0000] {processor.py:186} INFO - Started process (PID=1493) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:20.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:59:20.318+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:20.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:20.334+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:20.366+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:20.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:59:20.552+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:20.552+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:59:20.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.275 seconds
[2025-02-28T15:59:50.973+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T15:59:50.982+0000] {processor.py:186} INFO - Started process (PID=1513) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:50.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T15:59:50.986+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:50.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:51.002+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T15:59:51.033+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:51.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T15:59:51.065+0000] {logging_mixin.py:190} INFO - [2025-02-28T15:59:51.065+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T15:59:51.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T16:00:21.476+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:00:21.484+0000] {processor.py:186} INFO - Started process (PID=1533) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:21.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:00:21.490+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:21.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:21.508+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:21.540+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:21.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:00:21.573+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:21.573+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:00:21.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T16:00:52.012+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:00:52.021+0000] {processor.py:186} INFO - Started process (PID=1553) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:52.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:00:52.024+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:52.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:52.043+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:00:52.072+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:52.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:00:52.103+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:00:52.102+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:00:52.124+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T16:01:22.251+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:01:22.268+0000] {processor.py:186} INFO - Started process (PID=1573) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:22.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:01:22.271+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:22.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:22.287+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:22.320+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:22.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:01:22.354+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:22.354+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:01:22.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T16:01:52.839+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:01:52.849+0000] {processor.py:186} INFO - Started process (PID=1593) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:52.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:01:52.852+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:52.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:52.872+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:01:52.903+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:52.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:01:52.935+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:01:52.935+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:01:53.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.283 seconds
[2025-02-28T16:02:23.748+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:02:23.756+0000] {processor.py:186} INFO - Started process (PID=1613) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:23.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:02:23.760+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:23.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:23.778+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:23.811+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:23.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:02:23.850+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:23.849+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:02:23.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T16:02:54.457+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:02:54.470+0000] {processor.py:186} INFO - Started process (PID=1633) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:54.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:02:54.474+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:54.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:54.494+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:02:54.539+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:54.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:02:54.591+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:02:54.591+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:02:54.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.167 seconds
[2025-02-28T16:03:24.939+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:03:24.949+0000] {processor.py:186} INFO - Started process (PID=1653) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:24.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:03:24.953+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:24.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:24.969+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:25.001+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:25.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:03:25.034+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:25.034+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:03:25.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T16:03:55.519+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:03:55.531+0000] {processor.py:186} INFO - Started process (PID=1676) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:55.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:03:55.536+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:55.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:55.556+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:03:55.597+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:55.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:03:55.655+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:03:55.655+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:03:55.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.169 seconds
[2025-02-28T16:04:26.137+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:04:26.147+0000] {processor.py:186} INFO - Started process (PID=1696) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:26.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:04:26.151+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:26.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:26.167+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:26.200+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:26.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:04:26.238+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:26.237+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:04:26.267+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.134 seconds
[2025-02-28T16:04:56.347+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:04:56.358+0000] {processor.py:186} INFO - Started process (PID=1716) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:56.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:04:56.364+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:56.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:56.383+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:04:56.565+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:56.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:04:56.814+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:04:56.814+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:04:56.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.500 seconds
[2025-02-28T16:05:27.288+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:05:27.301+0000] {processor.py:186} INFO - Started process (PID=1736) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:27.302+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:05:27.306+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:27.306+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:27.326+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:27.368+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:27.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:05:27.415+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:27.415+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:05:27.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.162 seconds
[2025-02-28T16:05:57.876+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:05:57.886+0000] {processor.py:186} INFO - Started process (PID=1756) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:57.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:05:57.891+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:57.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:57.907+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:05:57.941+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:57.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:05:57.977+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:05:57.976+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:05:58.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.129 seconds
[2025-02-28T16:06:28.533+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:06:28.544+0000] {processor.py:186} INFO - Started process (PID=1776) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:28.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:06:28.548+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:28.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:28.569+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:28.610+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:28.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:06:28.649+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:28.648+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:06:28.675+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.146 seconds
[2025-02-28T16:06:58.910+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:06:58.920+0000] {processor.py:186} INFO - Started process (PID=1796) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:58.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:06:58.929+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:58.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:58.984+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:06:59.040+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:59.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:06:59.109+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:06:59.109+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:06:59.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.254 seconds
[2025-02-28T16:07:29.633+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:07:29.647+0000] {processor.py:186} INFO - Started process (PID=1819) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:07:29.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:07:29.652+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:07:29.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:07:29.673+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:07:29.730+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:07:29.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:07:29.773+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:07:29.773+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:07:29.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.347 seconds
[2025-02-28T16:08:00.116+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:08:00.131+0000] {processor.py:186} INFO - Started process (PID=1839) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:00.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:08:00.135+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:00.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:00.158+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:00.202+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:00.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:08:00.413+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:00.412+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:08:00.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.324 seconds
[2025-02-28T16:08:30.565+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:08:30.574+0000] {processor.py:186} INFO - Started process (PID=1859) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:30.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:08:30.578+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:30.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:30.593+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:08:30.625+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:30.625+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:08:30.656+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:08:30.656+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:08:30.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.116 seconds
[2025-02-28T16:09:01.202+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:09:01.211+0000] {processor.py:186} INFO - Started process (PID=1879) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:01.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:09:01.215+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:01.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:01.231+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:01.264+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:01.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:09:01.297+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:01.297+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:09:01.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T16:09:31.789+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:09:31.797+0000] {processor.py:186} INFO - Started process (PID=1899) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:31.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:09:31.801+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:31.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:31.816+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:09:31.847+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:31.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:09:31.879+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:09:31.879+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:09:31.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T16:10:02.304+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:10:02.315+0000] {processor.py:186} INFO - Started process (PID=1919) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:02.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:10:02.319+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:02.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:02.339+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:02.371+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:02.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:10:02.406+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:02.406+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:10:02.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.131 seconds
[2025-02-28T16:10:33.021+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:10:33.029+0000] {processor.py:186} INFO - Started process (PID=1939) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:33.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:10:33.034+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:33.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:33.051+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:10:33.084+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:33.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:10:33.289+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:10:33.288+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:10:33.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.302 seconds
[2025-02-28T16:11:03.923+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:11:03.936+0000] {processor.py:186} INFO - Started process (PID=1959) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:03.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:11:03.941+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:03.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:03.958+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:03.992+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:03.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:11:04.026+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:04.026+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:11:04.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.131 seconds
[2025-02-28T16:11:34.315+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:11:34.323+0000] {processor.py:186} INFO - Started process (PID=1979) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:34.324+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:11:34.327+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:34.327+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:34.343+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:11:34.374+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:34.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:11:34.408+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:11:34.408+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:11:34.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T16:12:04.927+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:12:04.936+0000] {processor.py:186} INFO - Started process (PID=1999) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:04.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:12:04.940+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:04.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:04.958+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:04.993+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:04.992+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:12:05.033+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:05.032+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:12:05.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.136 seconds
[2025-02-28T16:12:35.463+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:12:35.471+0000] {processor.py:186} INFO - Started process (PID=2019) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:35.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:12:35.475+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:35.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:35.491+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:12:35.521+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:35.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:12:35.555+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:12:35.555+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:12:35.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T16:13:06.157+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:13:06.165+0000] {processor.py:186} INFO - Started process (PID=2039) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:06.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:13:06.169+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:06.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:06.185+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:06.212+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:06.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:13:06.239+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:06.239+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:13:06.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.264 seconds
[2025-02-28T16:13:36.986+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:13:36.994+0000] {processor.py:186} INFO - Started process (PID=2059) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:36.994+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:13:36.996+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:36.996+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:37.008+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:13:37.033+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:37.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:13:37.215+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:13:37.215+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:13:37.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.254 seconds
[2025-02-28T16:14:07.312+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:14:07.321+0000] {processor.py:186} INFO - Started process (PID=2079) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:07.322+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:14:07.325+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:07.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:07.341+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:07.374+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:07.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:14:07.410+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:07.410+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:14:07.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.131 seconds
[2025-02-28T16:14:37.923+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:14:37.932+0000] {processor.py:186} INFO - Started process (PID=2099) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:37.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:14:37.937+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:37.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:37.955+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:14:37.989+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:37.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:14:38.024+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:14:38.024+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:14:38.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T16:15:08.480+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:15:08.491+0000] {processor.py:186} INFO - Started process (PID=2119) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:08.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:15:08.498+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:08.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:08.516+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:08.559+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:08.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:15:08.596+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:08.596+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:15:08.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.143 seconds
[2025-02-28T16:15:39.051+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:15:39.060+0000] {processor.py:186} INFO - Started process (PID=2139) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:39.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:15:39.064+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:39.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:39.081+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:15:39.114+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:39.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:15:39.148+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:15:39.148+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:15:39.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.129 seconds
[2025-02-28T16:16:09.839+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:16:09.853+0000] {processor.py:186} INFO - Started process (PID=2159) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:09.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:16:09.859+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:09.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:09.877+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:09.913+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:09.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:16:10.124+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:10.124+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:16:10.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.314 seconds
[2025-02-28T16:16:40.838+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:16:40.849+0000] {processor.py:186} INFO - Started process (PID=2179) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:40.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:16:40.853+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:40.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:40.870+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:16:40.908+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:40.908+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:16:40.947+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:16:40.947+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:16:40.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.137 seconds
[2025-02-28T16:17:11.473+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:17:11.482+0000] {processor.py:186} INFO - Started process (PID=2199) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:11.483+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:17:11.486+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:11.485+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:11.502+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:11.533+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:11.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:17:11.563+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:11.563+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:17:11.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T16:17:42.017+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:17:42.026+0000] {processor.py:186} INFO - Started process (PID=2219) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:42.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:17:42.031+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:42.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:42.050+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:17:42.086+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:42.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:17:42.123+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:17:42.123+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:17:42.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.133 seconds
[2025-02-28T16:18:12.557+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:18:12.564+0000] {processor.py:186} INFO - Started process (PID=2239) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:12.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:18:12.567+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:12.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:12.582+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:12.616+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:12.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:18:12.645+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:12.645+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:18:12.672+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.118 seconds
[2025-02-28T16:18:42.937+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:18:42.946+0000] {processor.py:186} INFO - Started process (PID=2259) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:42.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:18:42.950+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:42.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:42.966+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:18:42.999+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:42.999+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:18:43.036+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:18:43.036+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:18:43.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.286 seconds
[2025-02-28T16:19:13.880+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:19:13.889+0000] {processor.py:186} INFO - Started process (PID=2279) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:13.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:19:13.893+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:13.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:13.917+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:13.951+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:13.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:19:14.151+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:14.150+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:19:14.174+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.298 seconds
[2025-02-28T16:19:44.598+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:19:44.606+0000] {processor.py:186} INFO - Started process (PID=2299) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:44.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:19:44.609+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:44.609+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:44.625+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:19:44.659+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:44.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:19:44.696+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:19:44.696+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:19:44.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T16:20:15.483+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:20:15.492+0000] {processor.py:186} INFO - Started process (PID=2319) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:15.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:20:15.496+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:15.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:15.513+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:15.546+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:15.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:20:15.580+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:15.580+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:20:15.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T16:20:31.855+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:20:31.865+0000] {processor.py:186} INFO - Started process (PID=2329) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:31.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:20:31.871+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:31.870+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:31.892+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:20:32.297+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:32.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:20:32.334+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:20:32.333+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:20:32.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.509 seconds
[2025-02-28T16:21:03.092+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:21:03.101+0000] {processor.py:186} INFO - Started process (PID=2352) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:03.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:21:03.105+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:03.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:03.122+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:03.153+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:03.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:21:03.188+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:03.188+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:21:03.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.123 seconds
[2025-02-28T16:21:33.483+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:21:33.494+0000] {processor.py:186} INFO - Started process (PID=2372) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:33.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:21:33.497+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:33.497+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:33.515+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:21:33.550+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:33.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:21:33.591+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:21:33.591+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:21:33.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.341 seconds
[2025-02-28T16:22:04.390+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:22:04.401+0000] {processor.py:186} INFO - Started process (PID=2392) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:04.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:22:04.405+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:04.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:04.423+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:04.459+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:04.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:22:04.697+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:04.696+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:22:04.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.335 seconds
[2025-02-28T16:22:35.404+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:22:35.418+0000] {processor.py:186} INFO - Started process (PID=2412) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:35.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:22:35.423+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:35.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:35.450+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:22:35.499+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:35.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:22:35.543+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:22:35.543+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:22:35.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.171 seconds
[2025-02-28T16:23:06.282+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:23:06.290+0000] {processor.py:186} INFO - Started process (PID=2432) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:06.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:23:06.294+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:06.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:06.312+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:06.348+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:06.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:23:06.384+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:06.384+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:23:06.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.132 seconds
[2025-02-28T16:23:36.918+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:23:36.932+0000] {processor.py:186} INFO - Started process (PID=2452) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:36.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:23:36.938+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:36.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:36.959+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:23:36.999+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:36.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:23:37.062+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:23:37.062+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:23:37.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.178 seconds
[2025-02-28T16:24:07.393+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:24:07.402+0000] {processor.py:186} INFO - Started process (PID=2475) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:07.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:24:07.405+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:07.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:07.419+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:07.450+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:07.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:24:07.485+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:07.485+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:24:07.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.289 seconds
[2025-02-28T16:24:38.393+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:24:38.403+0000] {processor.py:186} INFO - Started process (PID=2495) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:38.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:24:38.412+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:38.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:38.430+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:24:38.475+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:38.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:24:38.687+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:24:38.686+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:24:38.714+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.325 seconds
[2025-02-28T16:25:08.867+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:25:08.877+0000] {processor.py:186} INFO - Started process (PID=2515) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:08.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:25:08.880+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:08.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:08.898+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:08.935+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:08.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:25:08.979+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:08.978+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:25:09.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.140 seconds
[2025-02-28T16:25:39.118+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:25:39.129+0000] {processor.py:186} INFO - Started process (PID=2535) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:39.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:25:39.133+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:39.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:39.149+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:25:39.186+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:39.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:25:39.224+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:25:39.224+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:25:39.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.134 seconds
[2025-02-28T16:26:09.773+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:26:09.782+0000] {processor.py:186} INFO - Started process (PID=2555) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:09.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:26:09.786+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:09.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:09.802+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:09.835+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:09.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:26:09.866+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:09.866+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:26:09.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.119 seconds
[2025-02-28T16:26:40.358+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:26:40.368+0000] {processor.py:186} INFO - Started process (PID=2575) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:40.369+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:26:40.372+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:40.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:40.387+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:26:40.422+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:40.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:26:40.458+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:26:40.458+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:26:40.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.140 seconds
[2025-02-28T16:27:10.839+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:27:10.847+0000] {processor.py:186} INFO - Started process (PID=2595) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:10.848+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:27:10.851+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:10.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:10.867+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:10.899+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:10.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:27:11.094+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:11.093+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:27:11.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.283 seconds
[2025-02-28T16:27:20.224+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:27:20.233+0000] {processor.py:186} INFO - Started process (PID=2610) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:20.234+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:27:20.237+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:20.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:20.260+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:20.290+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:20.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:27:20.492+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:20.492+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:27:20.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.295 seconds
[2025-02-28T16:27:21.275+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:27:21.284+0000] {processor.py:186} INFO - Started process (PID=2615) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:21.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:27:21.287+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:21.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:21.308+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:21.340+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:21.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:27:21.532+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:21.531+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:27:21.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.286 seconds
[2025-02-28T16:27:51.910+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:27:51.919+0000] {processor.py:186} INFO - Started process (PID=2635) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:51.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:27:51.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:51.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:51.939+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:27:51.972+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:51.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:27:52.160+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:27:52.159+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:27:52.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.274 seconds
[2025-02-28T16:28:23.065+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:28:23.073+0000] {processor.py:186} INFO - Started process (PID=2655) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:23.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:28:23.077+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:23.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:23.092+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:23.122+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:23.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:28:23.153+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:23.152+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:28:23.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T16:28:53.557+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:28:53.567+0000] {processor.py:186} INFO - Started process (PID=2675) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:53.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:28:53.571+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:53.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:53.589+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:28:53.619+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:53.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:28:53.651+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:28:53.650+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:28:53.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.120 seconds
[2025-02-28T16:29:24.099+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:29:24.111+0000] {processor.py:186} INFO - Started process (PID=2695) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:24.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:29:24.115+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:24.115+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:24.131+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:24.165+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:24.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:29:24.200+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:24.199+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:29:24.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.131 seconds
[2025-02-28T16:29:54.852+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:29:54.862+0000] {processor.py:186} INFO - Started process (PID=2715) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:54.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:29:54.865+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:54.865+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:54.883+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:29:54.918+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:54.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:29:55.125+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:29:55.124+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:29:55.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.305 seconds
[2025-02-28T16:30:25.735+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:30:25.744+0000] {processor.py:186} INFO - Started process (PID=2735) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:25.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:30:25.748+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:25.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:25.764+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:25.797+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:25.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:30:25.990+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:25.990+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:30:26.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.282 seconds
[2025-02-28T16:30:56.619+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:30:56.628+0000] {processor.py:186} INFO - Started process (PID=2755) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:56.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:30:56.633+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:56.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:56.648+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:30:56.681+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:56.681+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:30:56.722+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:30:56.721+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:30:56.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.145 seconds
[2025-02-28T16:31:27.220+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:31:27.228+0000] {processor.py:186} INFO - Started process (PID=2775) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:27.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:31:27.232+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:27.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:27.251+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:27.284+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:27.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:31:27.317+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:27.317+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:31:27.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.126 seconds
[2025-02-28T16:31:57.592+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:31:57.599+0000] {processor.py:186} INFO - Started process (PID=2795) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:57.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:31:57.602+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:57.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:57.616+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:31:57.642+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:57.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:31:57.678+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:31:57.677+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:31:57.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.112 seconds
[2025-02-28T16:32:28.337+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:32:28.345+0000] {processor.py:186} INFO - Started process (PID=2815) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:28.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:32:28.349+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:28.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:28.366+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:28.398+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:28.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:32:28.432+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:28.431+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:32:28.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.276 seconds
[2025-02-28T16:32:58.674+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:32:58.683+0000] {processor.py:186} INFO - Started process (PID=2835) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:58.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:32:58.686+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:58.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:58.703+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:32:58.737+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:58.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:32:58.941+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:32:58.941+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:32:58.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.294 seconds
[2025-02-28T16:33:29.239+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:33:29.254+0000] {processor.py:186} INFO - Started process (PID=2855) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:33:29.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:33:29.262+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:33:29.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:33:29.279+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:33:29.322+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:33:29.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:33:29.577+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:33:29.577+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:33:29.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.387 seconds
[2025-02-28T16:34:00.178+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:34:00.187+0000] {processor.py:186} INFO - Started process (PID=2875) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:00.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:34:00.192+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:00.192+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:00.209+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:00.242+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:00.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:34:00.278+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:00.278+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:34:00.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.128 seconds
[2025-02-28T16:34:30.711+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:34:30.720+0000] {processor.py:186} INFO - Started process (PID=2895) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:30.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:34:30.725+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:30.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:30.747+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:30.778+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:30.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:34:30.810+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:30.810+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:34:30.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.125 seconds
[2025-02-28T16:34:36.806+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:34:36.813+0000] {processor.py:186} INFO - Started process (PID=2900) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:36.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:34:36.817+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:36.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:36.839+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:36.876+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:36.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:34:36.915+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:36.915+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:34:36.942+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.140 seconds
[2025-02-28T16:34:37.926+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:34:37.938+0000] {processor.py:186} INFO - Started process (PID=2905) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:37.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:34:37.942+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:37.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:37.968+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:34:38.009+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:38.009+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:34:38.049+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:34:38.049+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:34:38.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.155 seconds
[2025-02-28T16:35:08.473+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:35:08.486+0000] {processor.py:186} INFO - Started process (PID=2925) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:08.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:35:08.493+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:08.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:08.514+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:08.553+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:08.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:35:08.593+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:08.593+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:35:08.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.152 seconds
[2025-02-28T16:35:38.787+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:35:38.795+0000] {processor.py:186} INFO - Started process (PID=2945) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:38.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:35:38.800+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:38.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:38.834+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:35:38.882+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:38.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:35:39.117+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:35:39.117+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:35:39.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.356 seconds
[2025-02-28T16:36:09.421+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:36:09.428+0000] {processor.py:186} INFO - Started process (PID=2965) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:09.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:36:09.431+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:09.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:09.444+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:09.470+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:09.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:36:09.635+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:09.635+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:36:09.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.238 seconds
[2025-02-28T16:36:40.530+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:36:40.545+0000] {processor.py:186} INFO - Started process (PID=2985) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:40.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:36:40.550+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:40.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:40.570+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:36:40.615+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:40.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:36:40.662+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:36:40.662+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:36:40.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.169 seconds
[2025-02-28T16:37:11.554+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:37:11.565+0000] {processor.py:186} INFO - Started process (PID=3005) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:11.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:37:11.569+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:11.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:11.585+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:11.618+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:11.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:37:11.654+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:11.654+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:37:11.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.130 seconds
[2025-02-28T16:37:42.173+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:37:42.183+0000] {processor.py:186} INFO - Started process (PID=3025) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:42.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:37:42.188+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:42.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:42.206+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:37:42.241+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:42.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:37:42.277+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:37:42.277+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:37:42.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.135 seconds
[2025-02-28T16:38:12.908+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:38:12.918+0000] {processor.py:186} INFO - Started process (PID=3045) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:12.919+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:38:12.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:12.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:12.940+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:12.976+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:12.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:38:13.015+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:13.014+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:38:13.215+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.312 seconds
[2025-02-28T16:38:43.520+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:38:43.528+0000] {processor.py:186} INFO - Started process (PID=3065) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:43.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:38:43.532+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:43.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:43.548+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:38:43.580+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:43.579+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:38:43.769+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:38:43.769+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:38:43.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.275 seconds
[2025-02-28T16:39:14.359+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:39:14.367+0000] {processor.py:186} INFO - Started process (PID=3085) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:14.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:39:14.371+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:14.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:14.386+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:14.561+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:14.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:39:14.591+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:14.590+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:39:14.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.257 seconds
[2025-02-28T16:39:45.388+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:39:45.397+0000] {processor.py:186} INFO - Started process (PID=3105) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:45.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:39:45.401+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:45.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:45.418+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:39:45.452+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:45.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:39:45.485+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:39:45.484+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:39:45.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T16:40:15.886+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:40:15.895+0000] {processor.py:186} INFO - Started process (PID=3125) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:15.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:40:15.899+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:15.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:15.918+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:15.950+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:15.950+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:40:15.982+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:15.982+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:40:16.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.122 seconds
[2025-02-28T16:40:46.273+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:40:46.279+0000] {processor.py:186} INFO - Started process (PID=3145) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:46.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:40:46.282+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:46.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:46.294+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:40:46.318+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:46.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:40:46.344+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:40:46.344+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:40:46.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.243 seconds
[2025-02-28T16:41:17.094+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:41:17.104+0000] {processor.py:186} INFO - Started process (PID=3165) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:17.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:41:17.108+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:17.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:17.124+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:17.157+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:17.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:41:17.397+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:17.396+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:41:17.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.335 seconds
[2025-02-28T16:41:47.966+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:41:47.973+0000] {processor.py:186} INFO - Started process (PID=3185) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:47.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:41:47.976+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:47.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:47.991+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:41:48.020+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:48.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:41:48.184+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:41:48.184+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:41:48.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.239 seconds
[2025-02-28T16:42:18.832+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:42:18.841+0000] {processor.py:186} INFO - Started process (PID=3205) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:18.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:42:18.845+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:18.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:18.863+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:18.893+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:18.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:42:18.925+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:18.924+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:42:18.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T16:42:49.135+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:42:49.146+0000] {processor.py:186} INFO - Started process (PID=3225) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:49.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:42:49.150+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:49.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:49.165+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:42:49.199+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:49.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:42:49.234+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:42:49.234+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:42:49.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.129 seconds
[2025-02-28T16:43:19.739+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:43:19.748+0000] {processor.py:186} INFO - Started process (PID=3245) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:19.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:43:19.751+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:19.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:19.767+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:19.802+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:19.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:43:19.835+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:19.835+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:43:19.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.123 seconds
[2025-02-28T16:43:50.449+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:43:50.466+0000] {processor.py:186} INFO - Started process (PID=3265) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:50.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:43:50.471+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:50.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:50.495+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:43:50.545+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:50.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:43:50.824+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:43:50.823+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:43:50.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.409 seconds
[2025-02-28T16:44:21.114+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:44:21.146+0000] {processor.py:186} INFO - Started process (PID=3285) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:21.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:44:21.160+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:21.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:21.193+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:21.254+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:21.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:44:21.628+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:21.627+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:44:21.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.579 seconds
[2025-02-28T16:44:51.792+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:44:51.801+0000] {processor.py:186} INFO - Started process (PID=3308) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:51.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:44:51.805+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:51.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:51.823+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:44:52.030+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:52.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:44:52.063+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:44:52.063+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:44:52.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.299 seconds
[2025-02-28T16:45:22.904+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:45:22.914+0000] {processor.py:186} INFO - Started process (PID=3328) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:22.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:45:22.918+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:22.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:22.933+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:22.967+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:22.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:45:23.002+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:23.002+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:45:23.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.125 seconds
[2025-02-28T16:45:53.392+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:45:53.401+0000] {processor.py:186} INFO - Started process (PID=3348) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:53.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:45:53.405+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:53.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:53.421+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:45:53.454+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:53.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:45:53.489+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:45:53.489+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:45:53.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.124 seconds
[2025-02-28T16:46:23.789+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:46:23.798+0000] {processor.py:186} INFO - Started process (PID=3368) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:23.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:46:23.802+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:23.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:23.818+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:23.851+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:23.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:46:23.886+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:23.885+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:46:24.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.290 seconds
[2025-02-28T16:46:54.816+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:46:54.826+0000] {processor.py:186} INFO - Started process (PID=3388) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:54.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:46:54.829+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:54.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:54.845+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:46:54.879+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:54.879+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:46:55.086+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:46:55.086+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:46:55.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.298 seconds
[2025-02-28T16:47:25.713+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:47:25.722+0000] {processor.py:186} INFO - Started process (PID=3408) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:25.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:47:25.726+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:25.725+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:25.741+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:25.776+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:25.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:47:25.978+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:25.978+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:47:26.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.292 seconds
[2025-02-28T16:47:56.334+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:47:56.343+0000] {processor.py:186} INFO - Started process (PID=3428) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:56.344+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:47:56.348+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:56.347+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:56.364+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:47:56.399+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:56.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:47:56.434+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:47:56.434+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:47:56.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.127 seconds
[2025-02-28T16:48:26.961+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:48:26.972+0000] {processor.py:186} INFO - Started process (PID=3451) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:26.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:48:26.977+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:26.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:26.995+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:27.031+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:27.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:48:27.072+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:27.071+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:48:27.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.142 seconds
[2025-02-28T16:48:57.355+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:48:57.366+0000] {processor.py:186} INFO - Started process (PID=3471) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:57.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:48:57.370+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:57.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:57.391+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:48:57.426+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:57.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:48:57.465+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:48:57.464+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:48:57.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.143 seconds
[2025-02-28T16:49:27.898+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:49:27.908+0000] {processor.py:186} INFO - Started process (PID=3491) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:27.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:49:27.911+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:27.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:27.927+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:27.958+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:27.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:49:28.146+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:28.145+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:49:28.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.275 seconds
[2025-02-28T16:49:58.800+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:49:58.810+0000] {processor.py:186} INFO - Started process (PID=3511) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:58.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:49:58.813+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:58.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:58.828+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:49:58.854+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:58.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:49:59.041+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:49:59.041+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:49:59.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.269 seconds
[2025-02-28T16:50:29.582+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:50:29.593+0000] {processor.py:186} INFO - Started process (PID=3531) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:50:29.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:50:29.598+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:50:29.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:50:29.616+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:50:29.896+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:50:29.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:50:29.927+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:50:29.927+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:50:29.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.370 seconds
[2025-02-28T16:51:00.573+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:51:00.583+0000] {processor.py:186} INFO - Started process (PID=3551) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:00.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:51:00.588+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:00.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:00.605+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:00.644+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:00.643+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:51:00.698+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:00.697+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:51:00.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.167 seconds
[2025-02-28T16:51:31.148+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:51:31.160+0000] {processor.py:186} INFO - Started process (PID=3571) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:31.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:51:31.165+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:31.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:31.184+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:51:31.224+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:31.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:51:31.258+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:51:31.257+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:51:31.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.141 seconds
[2025-02-28T16:52:02.050+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:52:02.059+0000] {processor.py:186} INFO - Started process (PID=3591) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:02.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:52:02.063+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:02.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:02.081+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:02.119+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:02.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:52:02.158+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:02.158+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:52:02.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.321 seconds
[2025-02-28T16:52:32.563+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:52:32.573+0000] {processor.py:186} INFO - Started process (PID=3611) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:32.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:52:32.577+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:32.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:32.593+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:52:32.627+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:32.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:52:32.836+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:52:32.836+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:52:32.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.300 seconds
[2025-02-28T16:53:02.990+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:53:02.999+0000] {processor.py:186} INFO - Started process (PID=3631) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:03.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:53:03.003+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:03.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:03.019+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:03.052+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:03.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:53:03.234+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:03.234+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:53:03.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.269 seconds
[2025-02-28T16:53:33.921+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:53:33.930+0000] {processor.py:186} INFO - Started process (PID=3651) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:33.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:53:33.934+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:33.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:33.950+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:53:33.981+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:33.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:53:34.013+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:53:34.012+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:53:34.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T16:54:04.309+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:54:04.318+0000] {processor.py:186} INFO - Started process (PID=3671) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:04.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:54:04.321+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:04.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:04.333+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:04.362+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:04.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:54:04.393+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:04.393+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:54:04.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.106 seconds
[2025-02-28T16:54:34.710+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:54:34.719+0000] {processor.py:186} INFO - Started process (PID=3691) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:34.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:54:34.723+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:34.722+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:34.738+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:54:34.768+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:34.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:54:34.799+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:54:34.799+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:54:34.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.114 seconds
[2025-02-28T16:55:05.272+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:55:05.278+0000] {processor.py:186} INFO - Started process (PID=3711) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:05.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:55:05.281+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:05.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:05.293+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:05.317+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:05.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:55:05.468+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:05.468+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:55:05.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.216 seconds
[2025-02-28T16:55:36.216+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:55:36.225+0000] {processor.py:186} INFO - Started process (PID=3731) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:36.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:55:36.228+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:36.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:36.243+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:55:36.286+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:36.286+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:55:36.472+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:55:36.471+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:55:36.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.280 seconds
[2025-02-28T16:56:06.747+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:56:06.755+0000] {processor.py:186} INFO - Started process (PID=3751) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:06.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:56:06.759+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:06.759+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:06.773+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:06.967+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:06.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:56:07.000+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:07.000+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:56:07.023+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.279 seconds
[2025-02-28T16:56:37.273+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:56:37.279+0000] {processor.py:186} INFO - Started process (PID=3771) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:37.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:56:37.282+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:37.282+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:37.296+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:56:37.326+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:37.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:56:37.358+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:56:37.358+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:56:37.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.107 seconds
[2025-02-28T16:57:07.686+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:57:07.695+0000] {processor.py:186} INFO - Started process (PID=3791) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:07.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:57:07.698+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:07.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:07.714+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:07.745+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:07.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:57:07.776+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:07.776+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:57:07.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.117 seconds
[2025-02-28T16:57:38.464+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:57:38.472+0000] {processor.py:186} INFO - Started process (PID=3811) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:38.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:57:38.475+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:38.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:38.490+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:57:38.526+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:38.526+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:57:38.562+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:57:38.562+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:57:38.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.268 seconds
[2025-02-28T16:58:09.195+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T16:58:09.237+0000] {processor.py:186} INFO - Started process (PID=3831) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:58:09.238+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T16:58:09.254+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:58:09.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:58:09.322+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T16:58:09.441+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:58:09.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T16:58:10.184+0000] {logging_mixin.py:190} INFO - [2025-02-28T16:58:10.183+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T16:58:10.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 1.049 seconds
[2025-02-28T17:03:04.581+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:03:04.593+0000] {processor.py:186} INFO - Started process (PID=3852) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:04.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:03:04.599+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:04.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:04.630+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:04.682+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:04.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:03:04.719+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:04.719+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:03:04.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.185 seconds
[2025-02-28T17:03:35.216+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:03:35.254+0000] {processor.py:186} INFO - Started process (PID=3872) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:35.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:03:35.262+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:35.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:35.307+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:03:35.485+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:35.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:03:35.645+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:03:35.644+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:03:35.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.541 seconds
[2025-02-28T17:28:02.924+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:28:02.953+0000] {processor.py:186} INFO - Started process (PID=3893) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:02.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:28:02.960+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:02.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:03.075+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:03.350+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:03.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:28:03.471+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:03.471+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:28:03.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.584 seconds
[2025-02-28T17:28:33.965+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:28:34.005+0000] {processor.py:186} INFO - Started process (PID=3913) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:34.007+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:28:34.016+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:34.014+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:34.069+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:28:34.261+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:34.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:28:34.436+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:28:34.435+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:28:34.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.579 seconds
[2025-02-28T17:41:29.671+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:41:29.718+0000] {processor.py:186} INFO - Started process (PID=3934) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:41:29.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:41:29.741+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:41:29.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:41:29.770+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:41:29.856+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:41:29.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:41:29.923+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:41:29.922+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:41:29.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.294 seconds
[2025-02-28T17:42:00.274+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:42:00.315+0000] {processor.py:186} INFO - Started process (PID=3954) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:00.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:42:00.324+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:00.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:00.378+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:00.553+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:00.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:42:00.704+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:00.703+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:42:00.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.550 seconds
[2025-02-28T17:42:31.317+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:42:31.371+0000] {processor.py:186} INFO - Started process (PID=3974) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:31.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:42:31.393+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:31.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:31.482+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:42:31.677+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:31.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:42:31.806+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:42:31.804+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:42:31.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.610 seconds
[2025-02-28T17:59:08.654+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:59:08.683+0000] {processor.py:186} INFO - Started process (PID=3994) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:08.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:59:08.757+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:08.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:08.809+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:08.892+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:08.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:59:08.954+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:08.954+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:59:09.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.355 seconds
[2025-02-28T17:59:39.168+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T17:59:39.228+0000] {processor.py:186} INFO - Started process (PID=4014) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:39.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T17:59:39.241+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:39.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:39.318+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T17:59:39.486+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:39.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T17:59:39.621+0000] {logging_mixin.py:190} INFO - [2025-02-28T17:59:39.619+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T17:59:39.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.564 seconds
[2025-02-28T18:16:38.734+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:16:38.744+0000] {processor.py:186} INFO - Started process (PID=4039) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:16:38.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:16:38.748+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:16:38.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:16:38.762+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:16:38.824+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:16:38.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:16:38.867+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:16:38.867+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:16:38.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.175 seconds
[2025-02-28T18:17:09.037+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:17:09.094+0000] {processor.py:186} INFO - Started process (PID=4059) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:09.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:17:09.103+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:09.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:09.155+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:09.328+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:09.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:17:09.472+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:09.471+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:17:09.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.543 seconds
[2025-02-28T18:17:40.064+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:17:40.110+0000] {processor.py:186} INFO - Started process (PID=4079) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:40.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:17:40.119+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:40.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:40.172+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:17:40.352+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:40.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:17:40.534+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:17:40.532+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:17:40.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.587 seconds
[2025-02-28T18:18:11.551+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:18:11.596+0000] {processor.py:186} INFO - Started process (PID=4099) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:18:11.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:18:11.607+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:18:11.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:18:11.656+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:18:11.820+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:18:11.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:18:11.959+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:18:11.958+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:18:12.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.518 seconds
[2025-02-28T18:35:55.663+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:35:55.677+0000] {processor.py:186} INFO - Started process (PID=4119) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:35:55.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:35:55.681+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:35:55.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:35:55.703+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:35:56.139+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:35:56.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:35:56.247+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:35:56.244+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:35:56.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.718 seconds
[2025-02-28T18:36:26.947+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:36:26.996+0000] {processor.py:186} INFO - Started process (PID=4139) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:36:26.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:36:27.006+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:36:27.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:36:27.059+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:36:27.235+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:36:27.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:36:27.373+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:36:27.372+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:36:27.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.544 seconds
[2025-02-28T18:54:28.406+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:54:28.429+0000] {processor.py:186} INFO - Started process (PID=4160) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:28.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:54:28.435+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:28.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:28.467+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:28.721+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:28.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:54:28.874+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:28.874+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:54:28.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.523 seconds
[2025-02-28T18:54:59.379+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:54:59.425+0000] {processor.py:186} INFO - Started process (PID=4180) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:59.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:54:59.436+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:59.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:59.503+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:54:59.675+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:59.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:54:59.805+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:54:59.803+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:54:59.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.526 seconds
[2025-02-28T18:58:47.006+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:58:47.027+0000] {processor.py:186} INFO - Started process (PID=4200) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:58:47.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:58:47.037+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:58:47.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:58:47.052+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:58:47.112+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:58:47.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:58:47.159+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:58:47.158+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:58:47.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.375 seconds
[2025-02-28T18:59:17.695+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:59:17.751+0000] {processor.py:186} INFO - Started process (PID=4221) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:17.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:59:17.763+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:17.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:17.819+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:18.022+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:18.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:59:18.227+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:18.225+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:59:18.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.665 seconds
[2025-02-28T18:59:48.693+0000] {logging_mixin.py:190} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:470 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2025-02-28T18:59:48.738+0000] {processor.py:186} INFO - Started process (PID=4241) to work on /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:48.743+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/transformed_data_dag.py for tasks to queue
[2025-02-28T18:59:48.751+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:48.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:48.817+0000] {processor.py:925} INFO - DAG(s) 's3_to_redshift_using_glue' retrieved from /opt/airflow/dags/transformed_data_dag.py
[2025-02-28T18:59:49.049+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:49.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-28T18:59:49.237+0000] {logging_mixin.py:190} INFO - [2025-02-28T18:59:49.235+0000] {dag.py:4180} INFO - Setting next_dagrun for s3_to_redshift_using_glue to 2025-02-28 00:00:00+00:00, run_after=2025-03-01 00:00:00+00:00
[2025-02-28T18:59:49.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/transformed_data_dag.py took 0.679 seconds
